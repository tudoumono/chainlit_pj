"""
Electronç”¨REST APIã‚µãƒ¼ãƒãƒ¼
Chainlitã¨ä¸¦è¡Œã—ã¦å‹•ä½œã—ã€Electronç®¡ç†æ©Ÿèƒ½ç”¨ã®APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æä¾›
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import asyncio
from typing import Dict, Any, List, Optional
import sqlite3
import json
import os
from dotenv import load_dotenv
from datetime import datetime
import time
from openai import AsyncOpenAI

# æ—¢å­˜ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆä¾å­˜ã”ã¨ã«ç‹¬ç«‹ã—ã¦èª­ã¿è¾¼ã¿ã€ç‰‡æ–¹ã®å¤±æ•—ã§å…¨ä½“ã‚’è½ã¨ã•ãªã„ï¼‰
persona_handler_instance = None
analytics_handler_instance = None
vector_store_handler = None
SQLiteDataLayer = None
app_logger = None

try:
    from handlers.persona_handler import persona_handler_instance  # type: ignore
except Exception as e:
    print(f"Warning: persona_handler not available: {e}")

try:
    # Electron APIã§ã¯analytics.dbã‚’ç›´æ¥å‚ç…§ã—ã¦é›†è¨ˆã™ã‚‹ãŸã‚ã€
    # handlers.analytics_handler ã¸ã®ä¾å­˜ã¯å¿…é ˆã§ã¯ãªã„ã€‚
    # å°†æ¥çš„ãªæ‹¡å¼µã«å‚™ãˆã¦èª­ã¿è¾¼ã¿ã‚’è©¦ã¿ã‚‹ãŒã€å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œã™ã‚‹ã€‚
    from handlers.analytics_handler import analytics_handler  # type: ignore
    analytics_handler_instance = analytics_handler
except Exception as e:
    print(f"Warning: analytics_handler not available: {e}")

try:
    from utils.vector_store_handler import vector_store_handler  # type: ignore
except Exception as e:
    print(f"Warning: vector_store_handler not available: {e}")

try:
    from data_layer import SQLiteDataLayer  # type: ignore
except Exception as e:
    print(f"Warning: SQLiteDataLayer not available: {e}")

try:
    from utils.logger import app_logger  # type: ignore
except Exception as e:
    print(f"Warning: app_logger not available: {e}")

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆDOTENV_PATHå„ªå…ˆï¼‰
_dotenv_path = os.environ.get("DOTENV_PATH")
if _dotenv_path and os.path.exists(_dotenv_path):
    load_dotenv(_dotenv_path)
else:
    load_dotenv()

# .envèª­ã¿è¾¼ã¿å¾Œã«Vector Store Handlerã‚’å†åˆæœŸåŒ–
try:
    if 'vector_store_handler' in globals() and vector_store_handler is not None:
        api_key = os.getenv("OPENAI_API_KEY", "")
        if api_key:
            # APIã‚­ãƒ¼ã‚’åæ˜ ã—ã¤ã¤ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå†åˆæœŸåŒ–
            try:
                vector_store_handler.update_api_key(api_key)
            except Exception:
                # update_api_keyãŒå¤±æ•—ã—ãŸå ´åˆã¯ç›´æ¥åˆæœŸåŒ–ã‚’è©¦ã¿ã‚‹
                vector_store_handler._init_clients()
        else:
            # APIã‚­ãƒ¼ãŒç©ºã§ã‚‚åˆæœŸåŒ–ã ã‘ã¯å®Ÿè¡Œï¼ˆãƒ­ã‚°ã«è­¦å‘ŠãŒå‡ºã‚‹ï¼‰
            vector_store_handler._init_clients()
except Exception as _e:
    print(f"Vector store handler reinit failed: {_e}")

app = FastAPI(
    title="Chainlit Electron API",
    description="Electronã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®APIç®¡ç†æ©Ÿèƒ½",
    version="1.0.0"
)

# å†…éƒ¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£: Vector Store Handlerã®åˆæœŸåŒ–ä¿è¨¼
def _ensure_vector_store_ready() -> bool:
    try:
        global vector_store_handler
        if not vector_store_handler:
            return False
        if getattr(vector_store_handler, 'async_client', None) is None:
            # .envåæ˜ å¾Œã®å†åˆæœŸåŒ–ã‚’è©¦è¡Œ
            api_key = os.getenv("OPENAI_API_KEY", "")
            if api_key:
                try:
                    vector_store_handler.update_api_key(api_key)
                except Exception:
                    vector_store_handler._init_clients()
            else:
                vector_store_handler._init_clients()
        return getattr(vector_store_handler, 'async_client', None) is not None
    except Exception:
        return False

# CORSè¨­å®šï¼ˆElectronã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹è¨±å¯ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "*"],  # Electron renderer
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®šç¾©
class PersonaData(BaseModel):
    name: str
    system_prompt: str
    model: Optional[str] = "gpt-3.5-turbo"
    temperature: Optional[float] = 0.7
    max_tokens: Optional[int] = 2000
    description: Optional[str] = ""
    tags: Optional[str] = ""
    is_active: Optional[bool] = False

class PersonaStatusUpdate(BaseModel):
    is_active: bool


class CleanupResponse(BaseModel):
    removed_files: int
    removed_dirs: int
    details: Dict[str, int]


class FactoryResetRequest(BaseModel):
    confirm: bool = False
    preview: bool = False


def _safe_remove(path: str, counters: Dict[str, int]):
    try:
        if os.path.isdir(path):
            import shutil
            shutil.rmtree(path, ignore_errors=True)
            counters['dirs'] += 1
        elif os.path.isfile(path):
            os.remove(path)
            counters['files'] += 1
    except Exception:
        pass


def _collect_paths_for_cleanup() -> Dict[str, list]:
    """ãƒ­ãƒ¼ã‚«ãƒ«ã®ä¸€æ™‚/ç”Ÿæˆç‰©ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¯¾è±¡ã¨ã—ã¦åé›†ï¼ˆOpenAIå´ã¯å¯¾è±¡å¤–ï¼‰ã€‚"""
    targets: Dict[str, list] = {
        'db': [],
        'tmp': [],
        'logs': [],
        'exports': [],
        'uploads': []
    }
    base = os.getcwd()
    # SQLite DBï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿ï¼‰
    targets['db'].extend([
        os.path.join(base, '.chainlit', 'chainlit.db'),
        os.path.join(base, '.chainlit', 'analytics.db')
    ])
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«/ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    targets['tmp'].append(os.path.join(base, '.chainlit', 'vector_store_files'))
    # ãƒ­ã‚°ï¼ˆPythonå´æ—¢å®šãªã—ã€‚å­˜åœ¨ã™ã‚Œã°å‰Šé™¤ï¼‰
    targets['logs'].append(os.path.join(base, 'Log'))
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ/ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    targets['exports'].append(os.path.join(base, 'exports'))
    targets['uploads'].append(os.path.join(base, 'uploads'))
    return targets


@app.get('/api/system/export')
async def export_system_info():
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’JSONã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿ï¼‰ã€‚"""
    try:
        info = {
            'timestamp': datetime.now().isoformat(),
            'cwd': os.getcwd(),
            'env': {
                'DOTENV_PATH': os.environ.get('DOTENV_PATH'),
                'CHAINLIT_CONFIG_PATH': os.environ.get('CHAINLIT_CONFIG_PATH'),
            }
        }
        # ä¾å­˜/ãƒãƒ¼ã‚¸ãƒ§ãƒ³
        try:
            import sys
            import platform
            info['runtime'] = {
                'python': sys.version,
                'platform': platform.platform(),
            }
        except Exception:
            pass

        export_dir = 'exports'
        os.makedirs(export_dir, exist_ok=True)
        filename = f"system_info_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        export_path = os.path.join(export_dir, filename)
        with open(export_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, ensure_ascii=False, indent=2)

        return {"status": "success", "data": {"export_path": export_path, "filename": filename}}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post('/api/system/test-openai-key')
async def test_openai_key(request: Dict[str, Any]):
    """OpenAI APIã‚­ãƒ¼ç–é€šãƒ†ã‚¹ãƒˆï¼ˆæ—¢å­˜ã‚­ãƒ¼ä½¿ç”¨ãŒåŸºæœ¬ï¼‰ã€‚"""
    try:
        api_key = (request.get('api_key') or os.getenv('OPENAI_API_KEY') or '').strip()
        if not api_key or api_key == 'your_api_key_here':
            raise HTTPException(status_code=400, detail='APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“')

        # ãƒ¢ãƒ‡ãƒ«ã¯envå„ªå…ˆã€ãƒ€ãƒ¡ãªã‚‰å®‰å…¨ãªæ—¢å®šã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        model_env = (request.get('model') or os.getenv('DEFAULT_MODEL') or '').strip()
        safe_default = 'gpt-4o-mini'
        candidate_models = [m for m in [model_env, safe_default] if m]

        client = AsyncOpenAI(api_key=api_key)
        last_error = None
        import asyncio
        for mdl in candidate_models:
            try:
                t0 = time.monotonic()
                # 400å›é¿ã®ãŸã‚è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ä»˜ã‘ãšæœ€å°å‘¼ã³å‡ºã—
                resp = await client.responses.create(model=mdl, input='ping')
                dt_ms = int((time.monotonic() - t0) * 1000)
                return {"status": "success", "data": {"model": getattr(resp, 'model', mdl), "latency_ms": dt_ms, "ok": True}}
            except Exception as e:
                last_error = e
                await asyncio.sleep(0)  # yield
                continue
        raise HTTPException(status_code=500, detail=f'OpenAIç–é€šã‚¨ãƒ©ãƒ¼: {last_error}')
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f'OpenAIç–é€šã‚¨ãƒ©ãƒ¼: {e}')


@app.post('/api/system/cleanup')
async def system_cleanup() -> Dict[str, Any]:
    """ãƒ­ãƒ¼ã‚«ãƒ«ç”Ÿæˆç‰©ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã€‚OpenAIå´ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ç­‰ã¯å¯¾è±¡å¤–ã€‚"""
    try:
        targets = _collect_paths_for_cleanup()
        counters = {'files': 0, 'dirs': 0}
        for cat, paths in targets.items():
            for p in paths:
                if os.path.isdir(p):
                    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé…ä¸‹ã‚’å‰Šé™¤
                    import shutil
                    if os.path.exists(p):
                        shutil.rmtree(p, ignore_errors=True)
                        counters['dirs'] += 1
                elif os.path.isfile(p):
                    _safe_remove(p, counters)
        return {"status": "success", "data": CleanupResponse(removed_files=counters['files'], removed_dirs=counters['dirs'], details=counters).dict()}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post('/api/system/factory-reset')
async def factory_reset(req: FactoryResetRequest):
    """ã‚¢ãƒ—ãƒªç¯„å›²ã®å…¨ãƒ‡ãƒ¼ã‚¿ãƒªã‚»ãƒƒãƒˆï¼ˆOpenAI APIå´ã¯è§¦ã‚‰ãªã„ï¼‰ã€‚"""
    try:
        targets = _collect_paths_for_cleanup()
        # è¿½åŠ : personas.jsonï¼ˆå­˜åœ¨ã™ã‚Œã°ï¼‰
        targets.setdefault('personas', []).append(os.path.join(os.getcwd(), '.chainlit', 'personas.json'))

        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        preview_data: Dict[str, int] = {}
        for cat, paths in targets.items():
            count = 0
            for p in paths:
                if os.path.isdir(p):
                    if os.path.exists(p):
                        count += 1
                elif os.path.isfile(p):
                    if os.path.exists(p):
                        count += 1
            preview_data[cat] = count

        if req.preview and not req.confirm:
            return {"status": "success", "data": {"preview": preview_data}}

        if not req.confirm:
            raise HTTPException(status_code=400, detail="Confirmation required")

        # å‰Šé™¤å®Ÿè¡Œï¼ˆOpenAI APIå´ã®å‰Šé™¤å‘¼ã³å‡ºã—ã¯ä¸€åˆ‡è¡Œã‚ãªã„ï¼‰
        counters = {'files': 0, 'dirs': 0}
        for paths in targets.values():
            for p in paths:
                if os.path.isdir(p):
                    import shutil
                    shutil.rmtree(p, ignore_errors=True)
                    counters['dirs'] += 1
                elif os.path.isfile(p):
                    _safe_remove(p, counters)

        return {"status": "success", "data": {"removed_files": counters['files'], "removed_dirs": counters['dirs'], "note": "OpenAIå´ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ç­‰ã¯å¤‰æ›´ã—ã¦ã„ã¾ã›ã‚“"}}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

class VectorStoreData(BaseModel):
    name: str
    category: Optional[str] = "general"
    description: Optional[str] = ""

# SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¢ã‚¯ã‚»ã‚¹
def get_db_connection():
    """SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’å–å¾—"""
    try:
        conn = sqlite3.connect('.chainlit/chainlit.db')
        conn.row_factory = sqlite3.Row
        return conn
    except Exception as e:
        if app_logger:
            app_logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        raise HTTPException(status_code=500, detail=f"Database connection error: {e}")

# analytics.db æ¥ç¶šï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯Noneã‚’è¿”ã™ãƒ©ãƒƒãƒ‘ï¼‰
def get_analytics_db_connection():
    path = os.path.join('.chainlit', 'analytics.db')
    if not os.path.exists(path):
        return None
    try:
        conn = sqlite3.connect(path)
        conn.row_factory = sqlite3.Row
        return conn
    except Exception as e:
        try:
            if app_logger:
                app_logger.error(f"analytics.dbæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        except Exception:
            pass
        return None

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/api/health")
async def health_check():
    """APIã‚µãƒ¼ãƒãƒ¼ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "ok",
        "message": "Electron API Server is running",
        "timestamp": datetime.now().isoformat()
    }

# ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/api/system/status")
async def get_system_status():
    """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹æƒ…å ±ã‚’å–å¾—ï¼ˆUIãŒæœŸå¾…ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å«ã‚€ï¼‰"""
    try:
        import sys
        electron_version = os.environ.get('ELECTRON_VERSION', '')
        app_version = os.environ.get('APP_VERSION', '')
        python_version = sys.version.split(' ')[0]
        # Chainlitãƒãƒ¼ã‚¸ãƒ§ãƒ³å–å¾—
        try:
            import chainlit  # type: ignore
            chainlit_version = getattr(chainlit, '__version__', '')
        except Exception:
            chainlit_version = ''

        # DBçµ±è¨ˆ/çŠ¶æ…‹
        db_path = '.chainlit/chainlit.db'
        database_status = 'unknown'
        thread_count = 0
        persona_count = 0
        vector_store_count = 0
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) as count FROM threads")
            thread_count = cursor.fetchone()['count']
            cursor.execute("SELECT COUNT(*) as count FROM personas")
            persona_count = cursor.fetchone()['count']
            cursor.execute("SELECT COUNT(*) as count FROM user_vector_stores")
            vector_store_count = cursor.fetchone()['count']
            database_status = 'healthy'
            conn.close()
        except Exception:
            database_status = 'unhealthy'

        # OpenAIè¨­å®šçŠ¶æ…‹ï¼ˆç–é€šã¾ã§ã¯è¡Œã‚ãªã„ï¼‰
        openai_status = 'healthy' if os.getenv('OPENAI_API_KEY') else 'unknown'

        return {
            "status": "success",
            "data": {
                "app_version": app_version,
                "electron_version": electron_version,
                "python_version": python_version,
                "chainlit_version": chainlit_version,
                "threads": thread_count,
                "personas": persona_count,
                "vector_stores": vector_store_count,
                "database_path": db_path,
                "database_status": database_status,
                "openai_status": openai_status,
                "timestamp": datetime.now().isoformat()
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ãƒšãƒ«ã‚½ãƒŠç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/api/personas")
async def list_personas():
    """ãƒšãƒ«ã‚½ãƒŠä¸€è¦§å–å¾—"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("""
            SELECT id, name, system_prompt, model, temperature, max_tokens, 
                   description, tags, is_active, created_at, updated_at
            FROM personas
            ORDER BY created_at DESC
        """)
        personas = [dict(row) for row in cursor.fetchall()]
        conn.close()
        
        return {"status": "success", "data": personas}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/personas")
async def create_persona(persona_data: PersonaData):
    """ãƒšãƒ«ã‚½ãƒŠä½œæˆ"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO personas (name, system_prompt, model, temperature, max_tokens, 
                                description, tags, is_active, created_at, updated_at)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            persona_data.name,
            persona_data.system_prompt,
            persona_data.model,
            persona_data.temperature,
            persona_data.max_tokens,
            persona_data.description,
            persona_data.tags,
            persona_data.is_active,
            datetime.now().isoformat(),
            datetime.now().isoformat()
        ))
        
        persona_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return {"status": "success", "data": {"persona_id": persona_id}}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/personas/{persona_id}")
async def get_persona(persona_id: int):
    """ç‰¹å®šã®ãƒšãƒ«ã‚½ãƒŠå–å¾—"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM personas WHERE id = ?", (persona_id,))
        persona = cursor.fetchone()
        conn.close()
        
        if not persona:
            raise HTTPException(status_code=404, detail="Persona not found")
        
        return {"status": "success", "data": dict(persona)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/personas/{persona_id}")
async def update_persona(persona_id: int, persona_data: PersonaData):
    """ãƒšãƒ«ã‚½ãƒŠæ›´æ–°"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            UPDATE personas SET 
                name=?, system_prompt=?, model=?, temperature=?, max_tokens=?,
                description=?, tags=?, is_active=?, updated_at=?
            WHERE id=?
        """, (
            persona_data.name,
            persona_data.system_prompt, 
            persona_data.model,
            persona_data.temperature,
            persona_data.max_tokens,
            persona_data.description,
            persona_data.tags,
            persona_data.is_active,
            datetime.now().isoformat(),
            persona_id
        ))
        
        if cursor.rowcount == 0:
            raise HTTPException(status_code=404, detail="Persona not found")
        
        conn.commit()
        conn.close()
        
        return {"status": "success", "message": "Persona updated successfully"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.patch("/api/personas/{persona_id}/status")
async def update_persona_status(persona_id: int, payload: PersonaStatusUpdate):
    """ãƒšãƒ«ã‚½ãƒŠã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹ã®ã¿æ›´æ–°"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute(
            "UPDATE personas SET is_active=?, updated_at=? WHERE id=?",
            (payload.is_active, datetime.now().isoformat(), persona_id),
        )
        if cursor.rowcount == 0:
            raise HTTPException(status_code=404, detail="Persona not found")
        conn.commit()
        conn.close()
        return {"status": "success", "message": "Persona status updated"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/api/personas/{persona_id}")
async def delete_persona(persona_id: int):
    """ãƒšãƒ«ã‚½ãƒŠå‰Šé™¤"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("DELETE FROM personas WHERE id = ?", (persona_id,))
        
        if cursor.rowcount == 0:
            raise HTTPException(status_code=404, detail="Persona not found")
        
        conn.commit()
        conn.close()
        
        return {"status": "success", "message": "Persona deleted successfully"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆOpenAIã‚¢ã‚«ã‚¦ãƒ³ãƒˆå…¨ä½“ã®ä¸€è¦§ï¼‰
@app.get("/api/vectorstores")
async def list_vector_stores():
    """OpenAIã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«å­˜åœ¨ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®å…¨ä½“ä¸€è¦§ã‚’è¿”ã™ã€‚"""
    try:
        if not _ensure_vector_store_ready():
            raise HTTPException(status_code=503, detail="Vector store handler is not initialized")
        # å–å¾—ãƒ­ã‚°ï¼ˆå¯è¦³æ¸¬æ€§å‘ä¸Šï¼‰
        try:
            if app_logger:
                app_logger.info("ğŸ“ ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä¸€è¦§ å–å¾—é–‹å§‹ (OpenAIå…¨ä½“)")
        except Exception:
            pass
        stores = await vector_store_handler.list_vector_stores()
        try:
            if app_logger:
                app_logger.info("ğŸ“ ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä¸€è¦§ å–å¾—å®Œäº†", count=len(stores))
        except Exception:
            pass
        return {"status": "success", "data": stores}
    except HTTPException:
        raise
    except Exception as e:
        try:
            if app_logger:
                app_logger.error("âŒ ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä¸€è¦§ å–å¾—å¤±æ•—", error=str(e))
        except Exception:
            pass
        raise HTTPException(status_code=500, detail=str(e))


class CreateVectorStoreRequest(BaseModel):
    name: str
    expires_after_days: Optional[int] = None


@app.post("/api/vectorstores")
async def create_vector_store(req: CreateVectorStoreRequest):
    """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ä½œæˆ"""
    try:
        if not _ensure_vector_store_ready():
            raise HTTPException(status_code=503, detail="Vector store handler is not initialized")

        vs_id = await vector_store_handler.create_vector_store(name=req.name)
        if not vs_id:
            raise HTTPException(status_code=500, detail="Failed to create vector store")

        info = await vector_store_handler.get_vector_store_info(vs_id) or {"id": vs_id, "name": req.name}
        # ãƒ­ãƒ¼ã‚«ãƒ«DBã«ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ç™»éŒ²ï¼ˆç°¡æ˜“: user_id='admin'ï¼‰
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute(
                """
                INSERT INTO user_vector_stores (user_id, vector_store_id, created_at, updated_at)
                VALUES (?, ?, ?, ?)
                """,
                ("admin", vs_id, datetime.now().isoformat(), datetime.now().isoformat())
            )
            conn.commit()
            conn.close()
        except Exception:
            pass
        return {"status": "success", "data": info}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


class UpdateVectorStoreRequest(BaseModel):
    name: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None


@app.patch("/api/vectorstores/{vector_store_id}")
async def update_vector_store(vector_store_id: str, req: UpdateVectorStoreRequest):
    """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®æ›´æ–°ï¼ˆä¸»ã«è¡¨ç¤ºåå¤‰æ›´ï¼‰ã€‚"""
    try:
        if not _ensure_vector_store_ready():
            raise HTTPException(status_code=503, detail="Vector store handler is not initialized")

        # ç¾çŠ¶ã¯åå‰å¤‰æ›´ã®å¯¾å¿œã‚’å„ªå…ˆ
        ok = True
        if req.name:
            ok = await vector_store_handler.rename_vector_store(vector_store_id, req.name)
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãŒå¿…è¦ãªã‚‰ä»Šå¾Œã“ã“ã§å¯¾å¿œ
        if not ok:
            raise HTTPException(status_code=500, detail="Failed to update vector store")

        info = await vector_store_handler.get_vector_store_info(vector_store_id)
        if not info:
            raise HTTPException(status_code=404, detail="Vector store not found")
        return {"status": "success", "data": info}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/vectorstores/{vector_store_id}")
async def get_vector_store(vector_store_id: str):
    """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢è©³ç´°+ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§"""
    try:
        if not _ensure_vector_store_ready():
            raise HTTPException(status_code=503, detail="Vector store handler is not initialized")

        info = await vector_store_handler.get_vector_store_info(vector_store_id)
        if not info:
            raise HTTPException(status_code=404, detail="Vector store not found")

        files = await vector_store_handler.get_vector_store_files(vector_store_id)
        # rendereræœŸå¾…ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åˆã‚ã›ãŸç°¡æ˜“å¤‰æ›
        file_details = []
        for f in files:
            file_details.append({
                "id": f.get("id"),
                "filename": f.get("filename") or f.get("id"),
                "size": f.get("bytes") or f.get("size") or 0,
                "status": f.get("status", "processed"),
                "created_at": f.get("created_at")
            })

        info["file_details"] = file_details
        return {"status": "success", "data": info}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


class UploadToVectorStoreRequest(BaseModel):
    filename: str
    content: str  # data URLã¾ãŸã¯base64æ–‡å­—åˆ—
    size: Optional[int] = 0
    type: Optional[str] = None


@app.post("/api/vectorstores/{vector_store_id}/upload")
async def upload_to_vector_store(vector_store_id: str, req: UploadToVectorStoreRequest):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«è¿½åŠ """
    try:
        if not _ensure_vector_store_ready():
            raise HTTPException(status_code=503, detail="Vector store handler is not initialized")

        # contentãŒdata URLå½¢å¼ã®å ´åˆã«base64æœ¬ä½“ã‚’æŠ½å‡º
        content = req.content
        if "," in content:
            content = content.split(",", 1)[1]
        import base64
        try:
            file_bytes = base64.b64decode(content)
        except Exception:
            raise HTTPException(status_code=400, detail="Invalid file content encoding")

        # OpenAIã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        file_id = await vector_store_handler.upload_file_from_bytes(
            file_bytes=file_bytes,
            filename=req.filename,
            purpose="assistants"
        )
        if not file_id:
            raise HTTPException(status_code=500, detail="Failed to upload file")

        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«è¿½åŠ ï¼ˆãƒãƒ¼ãƒªãƒ³ã‚°å«ã‚€ï¼‰
        attached = await vector_store_handler.add_file_to_vector_store(vector_store_id, file_id)
        if not attached:
            raise HTTPException(status_code=500, detail="Failed to attach file to vector store")

        return {"status": "success", "data": {"file_id": file_id}}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/api/vectorstores/{vector_store_id}")
async def delete_vector_store(vector_store_id: str):
    """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢å‰Šé™¤"""
    try:
        if not _ensure_vector_store_ready():
            raise HTTPException(status_code=503, detail="Vector store handler is not initialized")

        ok = await vector_store_handler.delete_vector_store(vector_store_id)
        if not ok:
            raise HTTPException(status_code=500, detail="Failed to delete vector store")
        # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚‚å‰Šé™¤
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("DELETE FROM user_vector_stores WHERE vector_store_id = ?", (vector_store_id,))
            conn.commit()
            conn.close()
        except Exception:
            pass
        return {"status": "success"}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# åˆ†æãƒ»çµ±è¨ˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/api/analytics/dashboard/{user_id}")
async def get_analytics_dashboard(user_id: str):
    """åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        # æ¦‚è¦åˆè¨ˆ
        cursor.execute(
            "SELECT COUNT(*) as cnt FROM threads WHERE user_id = ? OR user_identifier = ?",
            (user_id, user_id),
        )
        total_chats = cursor.fetchone()[0]

        cursor.execute(
            """
            SELECT COUNT(s.id) as cnt
            FROM steps s
            JOIN threads t ON s.thread_id = t.id
            WHERE (t.user_id = ? OR t.user_identifier = ?)
            """,
            (user_id, user_id),
        )
        total_messages = cursor.fetchone()[0]

        # personas / vector stores ã¯å­˜åœ¨ã—ãªã„å ´åˆã‚’è€ƒæ…®
        total_personas = 0
        try:
            cursor.execute("SELECT COUNT(*) FROM personas")
            total_personas = cursor.fetchone()[0]
        except Exception:
            total_personas = 0

        total_vector_stores = 0
        try:
            cursor.execute(
                "SELECT COUNT(*) FROM user_vector_stores WHERE user_id = ?",
                (user_id,),
            )
            row = cursor.fetchone()
            total_vector_stores = row[0] if row else 0
        except Exception:
            total_vector_stores = 0

        conn.close()

        return {
            "status": "success",
            "data": {
                "total_chats": int(total_chats or 0),
                "total_messages": int(total_messages or 0),
                "total_vector_stores": int(total_vector_stores or 0),
                "total_personas": int(total_personas or 0),
                "generated_at": datetime.now().isoformat(),
            },
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/analytics/usage/{user_id}")
async def get_usage_analytics(user_id: str, period: str = "7d"):
    """ä½¿ç”¨çŠ¶æ³åˆ†æå–å¾—ï¼ˆrendererãŒæœŸå¾…ã™ã‚‹å½¢ã«æ•´å½¢ï¼‰"""
    try:
        # æœŸé–“
        days = 7 if period == "7d" else 30 if period == "30d" else 90 if period == "90d" else 30

        # æ—¥åˆ¥é›†è¨ˆï¼ˆChainlit DB: stepsãƒ™ãƒ¼ã‚¹ï¼‰
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute(
            """
            SELECT DATE(s.created_at) as date, COUNT(*) as cnt
            FROM steps s
            JOIN threads t ON s.thread_id = t.id
            WHERE (t.user_id = ? OR t.user_identifier = ?)
              AND s.created_at >= datetime('now', ?)
            GROUP BY DATE(s.created_at)
            ORDER BY date ASC
            """,
            (user_id, user_id, f"-{days} days"),
        )
        daily_rows = cursor.fetchall()
        daily_usage = [{"date": row[0], "count": row[1]} for row in daily_rows]

        # ç›´è¿‘ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ & æ©Ÿèƒ½åˆ¥é›†è¨ˆï¼ˆanalytics.dbãŒã‚ã‚Œã°åˆ©ç”¨ï¼‰
        feature_usage: List[Dict[str, Any]] = []
        recent_activities: List[Dict[str, Any]] = []
        aconn = get_analytics_db_connection()
        if aconn is not None:
            acur = aconn.cursor()
            # æ©Ÿèƒ½åˆ¥é›†è¨ˆ
            try:
                acur.execute(
                    """
                    SELECT action as feature_name, COUNT(*) as cnt
                    FROM user_actions
                    WHERE timestamp >= datetime('now', ?)
                      AND user_id = ?
                    GROUP BY action
                    ORDER BY cnt DESC
                    LIMIT 10
                    """,
                    (f"-{days} days", user_id),
                )
                feature_usage = [
                    {"feature_name": r[0], "count": r[1]} for r in acur.fetchall()
                ]
            except Exception:
                feature_usage = []

            # æœ€è¿‘ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£
            try:
                acur.execute(
                    """
                    SELECT action as type, target as description, timestamp
                    FROM user_actions
                    WHERE user_id = ?
                    ORDER BY timestamp DESC
                    LIMIT 20
                    """,
                    (user_id,),
                )
                recent_activities = [
                    {"type": r[0], "description": r[1], "timestamp": r[2]}
                    for r in acur.fetchall()
                ]
            except Exception:
                recent_activities = []
            try:
                aconn.close()
            except Exception:
                pass
        else:
            # ä»£æ›¿: analytics.dbãŒç„¡ã‘ã‚Œã°ç°¡æ˜“çš„ã«ç›´è¿‘ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã¨ã—ã¦è¿”ã™
            try:
                cursor.execute(
                    """
                    SELECT s.type as type, substr(coalesce(s.output, s.name, 'message'), 1, 40) as description, s.created_at
                    FROM steps s
                    JOIN threads t ON s.thread_id = t.id
                    WHERE (t.user_id = ? OR t.user_identifier = ?)
                    ORDER BY s.created_at DESC
                    LIMIT 20
                    """,
                    (user_id, user_id),
                )
                recent_activities = [
                    {"type": r[0] or "message", "description": r[1] or "", "timestamp": r[2]}
                    for r in cursor.fetchall()
                ]
            except Exception:
                recent_activities = []

        conn.close()

        return {
            "status": "success",
            "data": {
                "daily_usage": daily_usage,
                "feature_usage": feature_usage,
                "recent_activities": recent_activities,
            },
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/analytics/export/{user_id}")
async def export_analytics(user_id: str, format: str = "json"):
    """åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆjson/csv/ç°¡æ˜“pdfãƒ†ã‚­ã‚¹ãƒˆï¼‰ã€‚"""
    try:
        # ã¾ãšåŒAPIã§ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
        usage_res = await get_usage_analytics(user_id=user_id, period="30d")
        dash_res = await get_analytics_dashboard(user_id=user_id)

        export_data = {
            "generated_at": datetime.now().isoformat(),
            "user_id": user_id,
            "dashboard": dash_res.get("data", {}),
            "usage": usage_res.get("data", {}),
        }

        os.makedirs("exports", exist_ok=True)
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")

        if format.lower() == "json":
            filename = f"analytics_{user_id}_{ts}.json"
            path = os.path.join("exports", filename)
            with open(path, "w", encoding="utf-8") as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
        elif format.lower() == "csv":
            # ã‚·ãƒ³ãƒ—ãƒ«ã«daily_usageã‚’CSVå‡ºåŠ›
            filename = f"analytics_daily_{user_id}_{ts}.csv"
            path = os.path.join("exports", filename)
            import csv
            with open(path, "w", newline="", encoding="utf-8") as f:
                writer = csv.writer(f)
                writer.writerow(["date", "count"]) 
                for row in export_data.get("usage", {}).get("daily_usage", []):
                    writer.writerow([row.get("date"), row.get("count", 0)])
        elif format.lower() == "pdf":
            # ç°¡æ˜“: ãƒ†ã‚­ã‚¹ãƒˆã‚’.pdfæ‹¡å¼µã§ä¿å­˜ï¼ˆæœ¬æ ¼çš„ãªPDFç”Ÿæˆã¯åˆ¥PRã§ï¼‰
            filename = f"analytics_report_{user_id}_{ts}.pdf"
            path = os.path.join("exports", filename)
            report = [
                "Analytics Report",
                f"Generated: {export_data['generated_at']}",
                f"User: {user_id}",
                "",
                "Dashboard Summary:",
            ]
            for k, v in export_data.get("dashboard", {}).items():
                if k == "generated_at":
                    continue
                report.append(f"- {k}: {v}")
            report.append("")
            report.append("Daily Usage (last 30d):")
            for row in export_data.get("usage", {}).get("daily_usage", []):
                report.append(f"- {row.get('date')}: {row.get('count', 0)}")
            with open(path, "w", encoding="utf-8") as f:
                f.write("\n".join(report))
        else:
            raise HTTPException(status_code=400, detail="Unsupported export format")

        return {"status": "success", "data": {"export_path": path, "filename": filename}}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ãƒ­ã‚°ç®¡ç†ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/api/system/logs")
async def get_system_logs():
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°å–å¾—ï¼ˆ<userData>/logs ãŠã‚ˆã³å¾“æ¥ã® .chainlit/app.log ã‚’çµ±åˆï¼‰"""
    try:
        import os
        import itertools
        import io
        log_dir = os.getenv('LOG_DIR') or ''
        files = []
        if log_dir and os.path.isdir(log_dir):
            for name in [
                'main.log',
                'chainlit.out.log', 'chainlit.err.log',
                'electron-api.out.log', 'electron-api.err.log'
            ]:
                p = os.path.join(log_dir, name)
                if os.path.exists(p):
                    files.append(p)
        legacy = os.path.join('.chainlit', 'app.log')
        if os.path.exists(legacy):
            files.append(legacy)
        logs = []
        def tail_lines(path, n=100):
            try:
                with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.readlines()[-n:]
            except Exception:
                return []
        for fpath in files:
            lst = tail_lines(fpath, 50)
            if lst:
                logs.append(f"===== {os.path.basename(fpath)} =====\n")
                logs.extend(lst)
                if not lst[-1].endswith('
'):
                    logs.append('
')
        # ä½•ã‚‚ãªã‘ã‚Œã°ç©ºé…åˆ—
        return {"status": "success", "data": {"logs": logs}}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.post("/api/files/export")
async def export_data(request: Dict[str, Any]):
    """ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    try:
        data = request.get("data")
        filename = request.get("filename", "export.json")
        
        export_path = f"exports/{filename}"
        os.makedirs("exports", exist_ok=True)
        
        with open(export_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        return {
            "status": "success", 
            "data": {"export_path": export_path, "filename": filename}
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

def run_electron_api():
    """Electronç”¨APIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•"""
    import uvicorn
    uvicorn.run(
        app,
        host=os.getenv("ELECTRON_API_HOST", "127.0.0.1"),
        port=int(os.getenv("ELECTRON_API_PORT", "8001")),
        log_level="info",
        reload=False
    )

if __name__ == "__main__":
    run_electron_api()

# ====== System utilities (export/cleanup/reset/test key) ======

class TestOpenAIKeyRequest(BaseModel):
    api_key: Optional[str] = None
    model: Optional[str] = None


## (duplicate removed) older test-openai-key endpoint deleted
