"""
Phase 5 (SQLiteæ°¸ç¶šåŒ–ç‰ˆ + Responses API): Chainlitã®å±¥æ­´ç®¡ç†
- SQLiteãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨ã—ã¦å±¥æ­´ã‚’æ°¸ç¶šåŒ–
- OpenAI Responses API with Toolsæ©Ÿèƒ½ï¼ˆWebæ¤œç´¢ã€ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ï¼‰
- èªè¨¼æ©Ÿèƒ½ã«ã‚ˆã‚‹ä¿è­·
- è‡ªå‹•çš„ãªå±¥æ­´ç®¡ç†ï¼ˆæ°¸ç¶šçš„ã«ä¿å­˜ï¼‰
- è©³ç´°ãªãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ 

============================================================
é‡è¦: OpenAI SDKã¯Responses APIã‚’æ­£å¼ã«ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™
============================================================

å‚ç…§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:
- OpenAIå…¬å¼APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: https://platform.openai.com/docs/api-reference/responses
- ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: F:\10_code\AI_Workspace_App_Chainlit\openai_responseAPI_reference\
  - openai responseAPI reference (Text generation).md
  - openai responseAPI reference (Conversation state).md
  - openai responseAPI reference (Streaming API responses).md

ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯Responses APIã®ä»•æ§˜ã«å®Œå…¨ã«æº–æ‹ ã—ã¦å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ã€‚
SDKã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚„ç’°å¢ƒã«ã‚ˆã‚ŠResponses APIãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã€
Chat Completions APIã«è‡ªå‹•çš„ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ãŒã€
ã“ã‚Œã¯SDKãŒResponses APIã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ã¨ã„ã†æ„å‘³ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
"""

import chainlit as cl
from chainlit.types import ThreadDict
from dotenv import load_dotenv
import os
import auth  # èªè¨¼è¨­å®šã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from typing import Optional, Dict, List
from datetime import datetime
import json
import uuid  # ã‚¹ãƒ¬ãƒƒãƒ‰IDç”Ÿæˆç”¨
import chainlit.data as cl_data  # ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚¢ã‚¯ã‚»ã‚¹ç”¨

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.logger import app_logger

# ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆSQLiteã‚’å„ªå…ˆã—ã¦æ°¸ç¶šåŒ–ï¼‰
data_layer_type = None

# SQLiteãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ï¼ˆæ°¸ç¶šåŒ–ã®ãŸã‚ï¼‰
try:
    # SQLiteãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨ï¼ˆå„ªå…ˆï¼‰
    import data_layer
    data_layer_type = "SQLite (Persistent)"
    app_logger.info("âœ… SQLiteãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨")
    app_logger.info("ğŸ“ å±¥æ­´ã¯.chainlit/chainlit.dbã«æ°¸ç¶šåŒ–ã•ã‚Œã¾ã™")
    print("âœ… SQLiteãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨")
    print("ğŸ“ å±¥æ­´ã¯.chainlit/chainlit.dbã«æ°¸ç¶šåŒ–ã•ã‚Œã¾ã™")
except Exception as e:
    app_logger.error(f"âš ï¸ SQLiteãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ã‚¨ãƒ©ãƒ¼: {e}")
    print(f"âš ï¸ SQLiteãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ã‚¨ãƒ©ãƒ¼: {e}")
    try:
        # ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä½¿ç”¨
        import simple_data_layer
        data_layer_type = "Simple In-Memory"
        app_logger.info("âœ… ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨")
        print("âœ… ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨")
        print("ğŸ“ æ³¨æ„: å±¥æ­´ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†èµ·å‹•ã§æ¶ˆå¤±ã—ã¾ã™")
    except ImportError:
        try:
            # SQLAlchemyDataLayerã‚’è©¦ã™ï¼ˆPostgreSQLï¼‰
            import chainlit.data as cl_data
            from chainlit.data.sql_alchemy import SQLAlchemyDataLayer
            
            # PostgreSQLæ¥ç¶šæ–‡å­—åˆ—ï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã‚€ï¼‰
            pg_conninfo = os.getenv("POSTGRES_CONNECTION_STRING")
            if pg_conninfo:
                cl_data._data_layer = SQLAlchemyDataLayer(conninfo=pg_conninfo)
                data_layer_type = "SQLAlchemy (PostgreSQL)"
                app_logger.info("âœ… SQLAlchemyDataLayerï¼ˆPostgreSQLï¼‰ã‚’ä½¿ç”¨")
                print("âœ… SQLAlchemyDataLayerï¼ˆPostgreSQLï¼‰ã‚’ä½¿ç”¨")
            else:
                app_logger.warning("âš ï¸ PostgreSQLæ¥ç¶šæ–‡å­—åˆ—ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                print("âš ï¸ PostgreSQLæ¥ç¶šæ–‡å­—åˆ—ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                print("ğŸ“ å±¥æ­´æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€data_layerã¾ãŸã¯")
                print("   simple_data_layer.pyã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        except Exception as e:
            app_logger.error(f"âš ï¸ SQLAlchemyDataLayerã®ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âš ï¸ SQLAlchemyDataLayerã®ã‚¨ãƒ©ãƒ¼: {e}")
            print("ğŸ“ data_layer.pyã¾ãŸã¯simple_data_layer.pyã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")

# utils ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆè¨­å®šç®¡ç†ã¨APIå‘¼ã³å‡ºã—ã®ã¿ä½¿ç”¨ï¼‰
from utils.config import config_manager
from utils.responses_handler import responses_handler
from utils.tools_config import tools_config
from utils.persona_manager import persona_manager  # Phase 6: ãƒšãƒ«ã‚½ãƒŠç®¡ç†

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
APP_NAME = "AI Workspace"
VERSION = "0.8.0 (Phase 6: Personas + Advanced Settings)"


@cl.on_chat_resume
async def on_chat_resume(thread: ThreadDict):
    """
    å±¥æ­´ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆã‚’å¾©å…ƒã™ã‚‹éš›ã®å‡¦ç†
    éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”»é¢ã«å†è¡¨ç¤ºã™ã‚‹
    """
    app_logger.info(f"ğŸ“‚ on_chat_resumeãŒå‘¼ã°ã‚Œã¾ã—ãŸ", 
                   thread_id=thread.get('id', 'None')[:8],
                   thread_name=thread.get('name', 'None'),
                   steps_count=len(thread.get('steps', [])))
    
    print(f"ğŸ“‚ on_chat_resumeãŒå‘¼ã°ã‚Œã¾ã—ãŸ")
    print(f"   Thread ID: {thread.get('id', 'None')}")
    print(f"   Thread Name: {thread.get('name', 'None')}")
    print(f"   Steps count: {len(thread.get('steps', []))}")
    
    # è¨­å®šã‚’èª­ã¿è¾¼ã¿
    settings = config_manager.get_all_settings()
    cl.user_session.set("settings", settings)
    cl.user_session.set("system_prompt", "")
    cl.user_session.set("message_count", 0)
    cl.user_session.set("total_tokens", 0)
    cl.user_session.set("previous_response_id", None)
    cl.user_session.set("message_history", [])
    cl.user_session.set("thread_id", thread.get("id"))
    cl.user_session.set("previous_response_id", None)
    cl.user_session.set("message_history", [])
    
    # å¾©å…ƒé€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    await cl.Message(
        content=f"ğŸ“‚ éå»ã®ä¼šè©±ã‚’å¾©å…ƒä¸­: {thread.get('name', 'Untitled')}...",
        author="System"
    ).send()
    
    # ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å†æ§‹ç¯‰ã—ã¦è¡¨ç¤º
    steps = thread.get('steps', [])
    app_logger.debug(f"å¾©å…ƒã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(steps)}")
    print(f"   å¾©å…ƒã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(steps)}")
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é †ç•ªã«å¾©å…ƒ
    message_count = 0
    messages_to_display = []  # è¡¨ç¤ºã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸€æ™‚ä¿å­˜
    
    # ã‚¹ãƒ†ãƒƒãƒ—ã‚’å‡¦ç†ã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡º
    for i, step in enumerate(steps):
        step_type = step.get('type')
        step_id = step.get('id')
        created_at = step.get('createdAt')
        
        app_logger.debug(f"ã‚¹ãƒ†ãƒƒãƒ—å‡¦ç† [{i+1}/{len(steps)}]", 
                        step_id=step_id[:8] if step_id else 'None',
                        type=step_type,
                        created_at=created_at,
                        has_input=bool(step.get('input')),
                        has_output=bool(step.get('output')))
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆ
        if step_type == 'user_message':
            user_input = step.get('input', '')
            if user_input:
                messages_to_display.append({
                    'type': 'user',
                    'content': user_input,
                    'id': step_id,
                    'created_at': created_at,
                    'order': i  # é †åºã‚’ä¿æŒ
                })
                app_logger.debug(f"ğŸ“¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æº–å‚™ [{i+1}]", preview=user_input[:50])
                print(f"   ğŸ“¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æº–å‚™ [{i+1}]: {user_input[:50]}...")
        
        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆ
        elif step_type == 'assistant_message':
            assistant_output = step.get('output', '')
            if assistant_output:
                messages_to_display.append({
                    'type': 'assistant',
                    'content': assistant_output,
                    'id': step_id,
                    'created_at': created_at,
                    'order': i  # é †åºã‚’ä¿æŒ
                })
                app_logger.debug(f"ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æº–å‚™ [{i+1}]", preview=assistant_output[:50])
                print(f"   ğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æº–å‚™ [{i+1}]: {assistant_output[:50]}...")
            else:
                app_logger.warning(f"âš ï¸ ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡ºåŠ›ãŒç©ºã§ã™ [{i+1}]", step_id=step_id[:8])
                print(f"   âš ï¸ ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡ºåŠ›ãŒç©ºã§ã™ [{i+1}]: {step_id[:8]}...")
        
        # runã‚¿ã‚¤ãƒ—ã¯ã‚·ã‚¹ãƒ†ãƒ çš„ãªã‚‚ã®ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—
        elif step_type == 'run':
            # runã‚¹ãƒ†ãƒƒãƒ—ã«ã‚‚outputãŒã‚ã‚‹å ´åˆãŒã‚ã‚‹
            run_output = step.get('output', '')
            if run_output and not run_output.startswith('{'):  # JSONã§ãªã„å ´åˆ
                # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦è¡¨ç¤º
                messages_to_display.append({
                    'type': 'system',
                    'content': run_output,
                    'id': step_id,
                    'created_at': created_at,
                    'order': i  # é †åºã‚’ä¿æŒ
                })
                app_logger.debug(f"ğŸ’» runã‚¹ãƒ†ãƒƒãƒ—ã®å‡ºåŠ›ã‚’æº–å‚™ [{i+1}]", preview=run_output[:50])
                print(f"   ğŸ’» runã‚¹ãƒ†ãƒƒãƒ—ã®å‡ºåŠ›ã‚’æº–å‚™ [{i+1}]: {run_output[:50]}...")
            else:
                app_logger.debug(f"â„¹ï¸ runã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ— [{i+1}]", name=step.get('name', 'N/A'))
                print(f"   â„¹ï¸ runã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ— [{i+1}]: {step.get('name', 'N/A')}")
        
        # ãã®ä»–ã®ã‚¿ã‚¤ãƒ—
        else:
            # å¿…è¦ã«å¿œã˜ã¦ä»–ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚¿ã‚¤ãƒ—ã‚‚å‡¦ç†
            app_logger.warning(f"âš ï¸ æœªå‡¦ç†ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚¿ã‚¤ãƒ— [{i+1}]: {step_type}")
            print(f"   âš ï¸ æœªå‡¦ç†ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚¿ã‚¤ãƒ— [{i+1}]: {step_type}")
            # outputãŒã‚ã‚Œã°è¡¨ç¤º
            other_output = step.get('output', '')
            if other_output:
                messages_to_display.append({
                    'type': 'system',
                    'content': other_output,
                    'id': step_id,
                    'created_at': created_at,
                    'order': i  # é †åºã‚’ä¿æŒ
                })
    
    # messages_to_displayã‚’orderã§ã‚½ãƒ¼ãƒˆã—ã¦ã‹ã‚‰è¡¨ç¤ºï¼ˆå¿µã®ãŸã‚ï¼‰
    messages_to_display.sort(key=lambda x: x.get('order', 0))
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é †ç•ªã«è¡¨ç¤º
    for msg in messages_to_display:
        if msg['type'] == 'user':
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            user_msg = cl.Message(
                content=msg['content'],
                author="User",
                type="user_message"
            )
            user_msg.id = msg['id']  # å…ƒã®IDã‚’ä¿æŒ
            await user_msg.send()
            message_count += 1
        elif msg['type'] == 'assistant':
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            assistant_msg = cl.Message(
                content=msg['content'],
                author="Assistant"
            )
            assistant_msg.id = msg['id']  # å…ƒã®IDã‚’ä¿æŒ
            await assistant_msg.send()
            message_count += 1
        elif msg['type'] == 'system':
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            system_msg = cl.Message(
                content=msg['content'],
                author="System"
            )
            system_msg.id = msg['id']  # å…ƒã®IDã‚’ä¿æŒ
            await system_msg.send()
            message_count += 1
    
    # å¾©å…ƒå®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    await cl.Message(
        content=f"âœ… å¾©å…ƒå®Œäº†: {message_count}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¾ã—ãŸ",
        author="System"
    ).send()
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã‚’æ›´æ–°
    cl.user_session.set("message_count", message_count)
    
    app_logger.history_restored(thread.get('id', 'unknown'), message_count)
    print(f"   âœ… å¾©å…ƒå®Œäº†: {message_count}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")


@cl.on_chat_start
async def on_chat_start():
    """
    æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã®å‡¦ç†
    """
    # è¨­å®šã‚’èª­ã¿è¾¼ã¿
    settings = config_manager.get_all_settings()
    cl.user_session.set("settings", settings)
    cl.user_session.set("system_prompt", "")
    cl.user_session.set("message_count", 0)
    cl.user_session.set("total_tokens", 0)
    
    # Phase 6: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒšãƒ«ã‚½ãƒŠã‚’åˆæœŸåŒ–
    await persona_manager.initialize_default_personas()
    
    # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒšãƒ«ã‚½ãƒŠã‚’å–å¾—ã—ã¦è¨­å®š
    active_persona = await persona_manager.get_active_persona()
    if active_persona:
        cl.user_session.set("active_persona", active_persona)
        cl.user_session.set("system_prompt", active_persona.get("system_prompt", ""))
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
        if active_persona.get("model"):
            settings["DEFAULT_MODEL"] = active_persona.get("model")
            cl.user_session.set("settings", settings)
    
    # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’å–å¾—
    current_user = cl.user_session.get("user")
    app_logger.info(f"ğŸ‘¤ æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹", user=current_user.identifier if current_user else "anonymous")
    print(f"ğŸ‘¤ ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼: {current_user}")
    
    # APIã‚­ãƒ¼ã®ç¢ºèª
    api_status = "âœ… è¨­å®šæ¸ˆã¿" if settings.get("OPENAI_API_KEY") and settings["OPENAI_API_KEY"] != "your_api_key_here" else "âš ï¸ æœªè¨­å®š"
    
    # Toolsæ©Ÿèƒ½ã®çŠ¶æ…‹ã‚’å–å¾—
    tools_status = "âœ… æœ‰åŠ¹" if tools_config.is_enabled() else "âŒ ç„¡åŠ¹"
    enabled_tools = tools_config.get_enabled_tools() if tools_config.is_enabled() else []
    
    welcome_message = f"""
# ğŸ¯ {APP_NAME} ã¸ã‚ˆã†ã“ãï¼

**Version**: {VERSION}

## ğŸ“Š ç¾åœ¨ã®çŠ¶æ…‹
- **APIã‚­ãƒ¼**: {api_status}
- **ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«**: {settings.get('DEFAULT_MODEL', 'gpt-4o-mini')}
- **ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼**: {data_layer_type or 'æœªè¨­å®š'}
- **Toolsæ©Ÿèƒ½**: {tools_status}
  {f"- æœ‰åŠ¹ãªãƒ„ãƒ¼ãƒ«: {', '.join(enabled_tools)}" if enabled_tools else ""}

## ğŸ”§ åˆ©ç”¨å¯èƒ½ãªã‚³ãƒãƒ³ãƒ‰
- `/help` - ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§ã¨ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º
- `/model [ãƒ¢ãƒ‡ãƒ«å]` - ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´
- `/system [ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ]` - ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š
- `/stats` - çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
- `/clear` - æ–°ã—ã„ä¼šè©±ã‚’é–‹å§‹
- `/setkey [APIã‚­ãƒ¼]` - OpenAI APIã‚­ãƒ¼ã‚’è¨­å®š
- `/tools` - Toolsæ©Ÿèƒ½ã®è¨­å®šã‚’è¡¨ç¤º
- `/tools enable [ãƒ„ãƒ¼ãƒ«å]` - ç‰¹å®šã®ãƒ„ãƒ¼ãƒ«ã‚’æœ‰åŠ¹åŒ–
- `/tools disable [ãƒ„ãƒ¼ãƒ«å]` - ç‰¹å®šã®ãƒ„ãƒ¼ãƒ«ã‚’ç„¡åŠ¹åŒ–
- `/persona` - ãƒšãƒ«ã‚½ãƒŠä¸€è¦§ã‚’è¡¨ç¤º
- `/persona [åå‰]` - ãƒšãƒ«ã‚½ãƒŠã‚’åˆ‡ã‚Šæ›¿ãˆ

ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: 
- ä¼šè©±ã¯æ°¸ç¶šçš„ã«ä¿å­˜ã•ã‚Œã¾ã™
- å·¦ä¸Šã®å±¥æ­´ãƒœã‚¿ãƒ³ã‹ã‚‰éå»ã®ä¼šè©±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™
- Toolsæ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€Webæ¤œç´¢ã‚„ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ãŒå¯èƒ½ã«ãªã‚Šã¾ã™

## ğŸ“ ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®çŠ¶æ…‹
- **ã‚¿ã‚¤ãƒ—**: {data_layer_type or 'âŒ æœªè¨­å®š'}
- **æ°¸ç¶šåŒ–**: {"âœ… SQLiteã«æ°¸ç¶šåŒ–" if data_layer_type == "SQLite (Persistent)" else "âœ… PostgreSQLã«æ°¸ç¶šåŒ–" if data_layer_type == "SQLAlchemy (PostgreSQL)" else "âš ï¸ ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªï¼ˆå†èµ·å‹•ã§æ¶ˆå¤±ï¼‰" if data_layer_type == "Simple In-Memory" else "âŒ ãªã—"}
- **èªè¨¼**: {"âœ… æœ‰åŠ¹" if os.getenv("CHAINLIT_AUTH_TYPE") == "credentials" else "âŒ ç„¡åŠ¹"}

---
**AIã¨ä¼šè©±ã‚’å§‹ã‚ã¾ã—ã‚‡ã†ï¼** ä½•ã§ã‚‚è³ªå•ã—ã¦ãã ã•ã„ã€‚
    """
    
    await cl.Message(content=welcome_message).send()
    
    # APIã‚­ãƒ¼ãŒæœªè¨­å®šã®å ´åˆã¯è­¦å‘Š
    if not settings.get("OPENAI_API_KEY") or settings["OPENAI_API_KEY"] == "your_api_key_here":
        await cl.Message(
            content="âš ï¸ **APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“**\n\n`/setkey [ã‚ãªãŸã®APIã‚­ãƒ¼]` ã‚³ãƒãƒ³ãƒ‰ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚",
            author="System"
        ).send()


@cl.on_message
async def on_message(message: cl.Message):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†
    ã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†ã¨AIå¿œç­”ã®ç”Ÿæˆãƒ»ä¿å­˜
    """
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡
    user_input = message.content
    current_user = cl.user_session.get("user")
    user_id = current_user.identifier if current_user else "anonymous"
    
    app_logger.message_received(user_input, user_id)
    app_logger.debug(f"ğŸ“¥ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡", 
                     user=user_id,
                     length=len(user_input),
                     thread_id=cl.context.session.thread_id[:8] if hasattr(cl.context.session, 'thread_id') else 'None')
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚«ã‚¦ãƒ³ãƒˆã‚’å¢—åŠ 
    message_count = cl.user_session.get("message_count", 0) + 1
    cl.user_session.set("message_count", message_count)
    
    # ã‚³ãƒãƒ³ãƒ‰å‡¦ç†
    if user_input.startswith("/"):
        await handle_command(user_input)
        return
    
    # AIå¿œç­”ã®ç”Ÿæˆ
    settings = cl.user_session.get("settings", {})
    api_key = settings.get("OPENAI_API_KEY")
    
    if not api_key or api_key == "your_api_key_here":
        await cl.Message(
            content="âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n`/setkey [APIã‚­ãƒ¼]` ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚",
            author="System"
        ).send()
        return
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    system_prompt = cl.user_session.get("system_prompt", "")
    model = settings.get("DEFAULT_MODEL", "gpt-4o-mini")
    
    app_logger.debug(f"ğŸ¤– AIå¿œç­”ç”Ÿæˆé–‹å§‹", model=model, has_system_prompt=bool(system_prompt))
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’ç®¡ç†
    message_history = cl.user_session.get("message_history", [])
    
    # Responses APIã‚’ä½¿ç”¨ã—ã¦AIå¿œç­”ã‚’ç”Ÿæˆ
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    
    # å±¥æ­´ã‚’è¿½åŠ ï¼ˆæœ€å¤§10ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
    messages.extend(message_history[-10:])
    messages.append({"role": "user", "content": user_input})
    
    # Toolsæ©Ÿèƒ½ã®çŠ¶æ…‹ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
    tools_enabled = tools_config.is_enabled()
    if tools_enabled:
        enabled_tools = tools_config.get_enabled_tools()
        app_logger.debug(f"ğŸ”§ Toolsæ©Ÿèƒ½æœ‰åŠ¹", tools=enabled_tools)
    
    # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…ˆã«ä½œæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ï¼‰
    ai_message = cl.Message(content="", author="Assistant")
    await ai_message.send()
    
    response_text = ""
    tool_calls = None
    previous_response_id = cl.user_session.get("previous_response_id")
    
    # ============================================================
    # Responses APIã‚’å‘¼ã³å‡ºã—ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æœ‰åŠ¹ï¼‰
    # OpenAI SDKã¯Responses APIã‚’æ­£å¼ã«ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™
    # å‚ç…§: openai responseAPI reference (Text generation).md
    # å‚ç…§: openai responseAPI reference (Conversation state).md
    # ============================================================
    async for chunk in responses_handler.create_response(
        messages=messages,
        model=model,
        stream=True,
        use_tools=tools_enabled,
        previous_response_id=previous_response_id
    ):
        if "error" in chunk:
            app_logger.error(f"API Error: {chunk['error']}")
            await ai_message.update(content=f"âŒ ã‚¨ãƒ©ãƒ¼: {chunk['error']}")
            response_text = None
            break
        
        # Responses APIã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†
        elif chunk.get("type") == "text_delta":
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ«ã‚¿ã‚¤ãƒ™ãƒ³ãƒˆ
            if chunk.get("content"):
                response_text += chunk["content"]
                await ai_message.stream_token(chunk["content"])
        
        elif chunk.get("type") == "response_complete":
            # å®Œäº†ã‚¤ãƒ™ãƒ³ãƒˆ
            if chunk.get("id"):
                cl.user_session.set("previous_response_id", chunk["id"])
            if chunk.get("output_text") and not response_text:
                response_text = chunk["output_text"]
                await ai_message.update(content=response_text)
            break
        
        # Chat Completions APIã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
        elif "choices" in chunk and chunk["choices"]:
            choice = chunk["choices"][0]
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆdeltaã‚’å‡¦ç†ï¼‰
            if "delta" in choice:
                delta = choice["delta"]
                
                # ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‡¦ç†
                if delta.get("content"):
                    response_text += delta["content"]
                    await ai_message.stream_token(delta["content"])
                
                # finish_reasonãŒã‚ã‚‹å ´åˆã¯å®Œäº†
                if choice.get("finish_reason"):
                    # response_idã‚’ä¿å­˜ï¼ˆä¼šè©±ç¶™ç¶šç”¨ï¼‰
                    if "id" in chunk:
                        cl.user_session.set("previous_response_id", chunk["id"])
                    break
            
            # éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆmessageã‚’å‡¦ç†ï¼‰
            elif "message" in choice:
                message_data = choice["message"]
                
                # é€šå¸¸ã®å¿œç­”
                if message_data.get("content"):
                    response_text = message_data["content"]
                    await ai_message.update(content=response_text)
            
            # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒã‚ã‚‹å ´åˆ
            if message_data.get("tool_calls"):
                tool_calls = message_data["tool_calls"]
                app_logger.debug(f"ğŸ”§ ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’æ¤œå‡º", count=len(tool_calls))
                
                # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’UIã«è¡¨ç¤ºï¼ˆè¨­å®šã«ã‚ˆã‚‹ï¼‰
                if tools_config.get_setting("show_tool_calls", True):
                    for tc in tool_calls:
                        tool_type = tc.get("type")
                        if tool_type == "web_search":
                            query = tc.get("web_search", {}).get("query", "")
                            await cl.Message(
                                content=f"ğŸ” **Webæ¤œç´¢ä¸­**: `{query}`",
                                author="System"
                            ).send()
                        elif tool_type == "file_search":
                            await cl.Message(
                                content=f"ğŸ“ **ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ä¸­**",
                                author="System"
                            ).send()
                
                # ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ
                tool_results = await responses_handler.handle_tool_calls(tool_calls, messages)
                
                # ãƒ„ãƒ¼ãƒ«çµæœã‚’è¡¨ç¤ºï¼ˆè¨­å®šã«ã‚ˆã‚‹ï¼‰
                if tools_config.get_setting("show_tool_results", True):
                    for result in tool_results:
                        await cl.Message(
                            content=f"ğŸ“Š **ãƒ„ãƒ¼ãƒ«çµæœ**:\n```\n{result['content'][:500]}...\n```",
                            author="System"
                        ).send()
                
                # ãƒ„ãƒ¼ãƒ«çµæœã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ 
                messages.append(message_data)
                messages.extend(tool_results)
                
                # ãƒ„ãƒ¼ãƒ«çµæœã‚’è¸ã¾ãˆã¦å†åº¦APIã‚’å‘¼ã³å‡ºã—
                final_msg = cl.Message(content="", author="Assistant")
                await final_msg.send()
                
                async for final_chunk in responses_handler.create_response(
                    messages=messages,
                    model=model,
                    stream=True,
                    use_tools=False,  # ãƒ„ãƒ¼ãƒ«ã¯ä¸€åº¦ã ã‘ä½¿ç”¨
                    previous_response_id=previous_response_id
                ):
                    # Responses APIã‚¤ãƒ™ãƒ³ãƒˆ
                    if final_chunk.get("type") == "text_delta":
                        if final_chunk.get("content"):
                            response_text += final_chunk["content"]
                            await final_msg.stream_token(final_chunk["content"])
                    
                    elif final_chunk.get("type") == "response_complete":
                        if final_chunk.get("output_text") and not response_text:
                            response_text = final_chunk["output_text"]
                            await final_msg.update(content=response_text)
                        break
                    
                    # Chat Completions APIãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    elif "choices" in final_chunk and final_chunk["choices"]:
                        final_choice = final_chunk["choices"][0]
                        
                        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
                        if "delta" in final_choice:
                            delta = final_choice["delta"]
                            if delta.get("content"):
                                response_text += delta["content"]
                                await final_msg.stream_token(delta["content"])
                            
                            if final_choice.get("finish_reason"):
                                break
                        
                        # éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
                        elif "message" in final_choice:
                            final_message = final_choice["message"]
                            if final_message.get("content"):
                                response_text = final_message["content"]
                                await final_msg.update(content=response_text)
                            break
            
            # response_idã‚’ä¿å­˜ï¼ˆä¼šè©±ç¶™ç¶šç”¨ï¼‰
            if "id" in chunk:
                cl.user_session.set("previous_response_id", chunk["id"])
            
            break
    
    if response_text:
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº†æ™‚ã®å‡¦ç†
        await ai_message.update()  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº†ã‚’é€šçŸ¥
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’æ›´æ–°
        message_history.append({"role": "user", "content": user_input})
        message_history.append({"role": "assistant", "content": response_text})
        
        # å±¥æ­´ã‚’20ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«åˆ¶é™
        if len(message_history) > 20:
            message_history = message_history[-20:]
        
        cl.user_session.set("message_history", message_history)
        
        # AIå¿œç­”ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        app_logger.ai_response(response_text, model)
        app_logger.debug(f"ğŸ¤– AIå¿œç­”é€ä¿¡å®Œäº†", 
                        length=len(response_text),
                        message_id=ai_message.id[:8] if ai_message.id else 'None')
        
        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’æ›´æ–°ï¼ˆç°¡æ˜“è¨ˆç®—ï¼‰
        total_tokens = cl.user_session.get("total_tokens", 0)
        estimated_tokens = len(user_input.split()) + len(response_text.split())
        total_tokens += estimated_tokens * 2  # æ¦‚ç®—
        cl.user_session.set("total_tokens", total_tokens)
        
        app_logger.debug(f"ğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡æ›´æ–°", 
                        estimated_tokens=estimated_tokens,
                        total_tokens=total_tokens)
    else:
        error_msg = "âŒ AIå¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
        await cl.Message(content=error_msg, author="System").send()
        app_logger.error(f"AIå¿œç­”ç”Ÿæˆå¤±æ•—", user_input=user_input[:100])
        await ai_message.update(content="âŒ AIå¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")


async def handle_command(user_input: str):
    """ã‚³ãƒãƒ³ãƒ‰ã‚’å‡¦ç†"""
    parts = user_input.split(maxsplit=2)
    cmd = parts[0].lower()
    
    app_logger.debug(f"ğŸ® ã‚³ãƒãƒ³ãƒ‰å‡¦ç†", command=cmd)
    
    if cmd == "/help":
        await show_help()
    elif cmd == "/model":
        if len(parts) > 1:
            await change_model(parts[1])
        else:
            await cl.Message(
                content="âŒ ãƒ¢ãƒ‡ãƒ«åã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\nä¾‹: `/model gpt-4o`",
                author="System"
            ).send()
    elif cmd == "/system":
        args = user_input[len("/system"):].strip() if len(user_input) > len("/system") else ""
        await set_system_prompt(args)
    elif cmd == "/stats":
        await show_statistics()
    elif cmd == "/clear":
        await start_new_chat()
    elif cmd == "/setkey":
        if len(parts) > 1:
            await set_api_key(parts[1])
        else:
            await cl.Message(
                content="âŒ APIã‚­ãƒ¼ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\nä¾‹: `/setkey sk-...`",
                author="System"
            ).send()
    elif cmd == "/test":
        await test_connection()
    elif cmd == "/status":
        await show_status()
    elif cmd == "/tools":
        if len(parts) == 1:
            await show_tools_status()
        elif len(parts) >= 3:
            await handle_tools_command(parts[1], parts[2])
        else:
            await cl.Message(
                content="âŒ ã‚³ãƒãƒ³ãƒ‰å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚\nä¾‹: `/tools enable web_search`",
                author="System"
            ).send()
    elif cmd == "/persona" or cmd == "/personas":
        if len(parts) == 1:
            await show_personas()
        elif len(parts) == 2:
            await switch_persona(parts[1])
        else:
            action = parts[1].lower()
            if action == "create":
                await create_persona_interactive()
            elif action == "delete":
                if len(parts) > 2:
                    await delete_persona(parts[2])
                else:
                    await cl.Message(
                        content="âŒ å‰Šé™¤ã™ã‚‹ãƒšãƒ«ã‚½ãƒŠåã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\nä¾‹: `/persona delete creative`",
                        author="System"
                    ).send()
            else:
                await switch_persona(parts[1])
    else:
        await cl.Message(
            content=f"âŒ ä¸æ˜ãªã‚³ãƒãƒ³ãƒ‰: {cmd}\n`/help` ã§ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
            author="System"
        ).send()


async def show_help():
    """ãƒ˜ãƒ«ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    help_message = """
# ğŸ“š ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§

## åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰
- `/help` - ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º
- `/clear` - æ–°ã—ã„ä¼šè©±ã‚’é–‹å§‹
- `/stats` - ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµ±è¨ˆã‚’è¡¨ç¤º
- `/status` - è¨­å®šçŠ¶æ…‹ã‚’è¡¨ç¤º

## è¨­å®šã‚³ãƒãƒ³ãƒ‰
- `/setkey [APIã‚­ãƒ¼]` - OpenAI APIã‚­ãƒ¼ã‚’è¨­å®š
- `/model [ãƒ¢ãƒ‡ãƒ«å]` - ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´
  - ä¾‹: `/model gpt-4o-mini`
  - ä¾‹: `/model gpt-4o`
- `/system [ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ]` - ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š
  - ä¾‹: `/system ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™`
- `/test` - APIæ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ

## Toolsæ©Ÿèƒ½ã‚³ãƒãƒ³ãƒ‰
- `/tools` - Toolsæ©Ÿèƒ½ã®ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º
- `/tools enable web_search` - Webæ¤œç´¢ã‚’æœ‰åŠ¹åŒ–
- `/tools disable web_search` - Webæ¤œç´¢ã‚’ç„¡åŠ¹åŒ–
- `/tools enable file_search` - ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚’æœ‰åŠ¹åŒ–
- `/tools disable file_search` - ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚’ç„¡åŠ¹åŒ–
- `/tools enable all` - ã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ«ã‚’æœ‰åŠ¹åŒ–
- `/tools disable all` - ã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ«ã‚’ç„¡åŠ¹åŒ–

## ğŸ’¡ ãƒ’ãƒ³ãƒˆ
- ä¼šè©±å±¥æ­´ã¯è‡ªå‹•çš„ã«ä¿å­˜ã•ã‚Œã¾ã™
- å·¦ä¸Šã®å±¥æ­´ãƒœã‚¿ãƒ³ã‹ã‚‰éå»ã®ä¼šè©±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™
- Toolsæ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€AIãŒå¿…è¦ã«å¿œã˜ã¦Webæ¤œç´¢ã‚„ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™
"""
    await cl.Message(content=help_message, author="System").send()


async def show_tools_status():
    """Toolsæ©Ÿèƒ½ã®çŠ¶æ…‹ã‚’è¡¨ç¤º"""
    status = "âœ… æœ‰åŠ¹" if tools_config.is_enabled() else "âŒ ç„¡åŠ¹"
    enabled_tools = tools_config.get_enabled_tools()
    
    tools_message = f"""
# ğŸ”§ Toolsæ©Ÿèƒ½ã®è¨­å®š

## å…¨ä½“ã®çŠ¶æ…‹
- **Toolsæ©Ÿèƒ½**: {status}

## å€‹åˆ¥ãƒ„ãƒ¼ãƒ«ã®çŠ¶æ…‹
- **Webæ¤œç´¢**: {"âœ… æœ‰åŠ¹" if tools_config.is_tool_enabled("web_search") else "âŒ ç„¡åŠ¹"}
- **ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢**: {"âœ… æœ‰åŠ¹" if tools_config.is_tool_enabled("file_search") else "âŒ ç„¡åŠ¹"}
- **ã‚³ãƒ¼ãƒ‰ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ãƒ¼**: {"âœ… æœ‰åŠ¹" if tools_config.is_tool_enabled("code_interpreter") else "âŒ ç„¡åŠ¹"}
- **ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°**: {"âœ… æœ‰åŠ¹" if tools_config.is_tool_enabled("custom_functions") else "âŒ ç„¡åŠ¹"}

## è¨­å®š
- **ãƒ„ãƒ¼ãƒ«é¸æŠ**: {tools_config.get_setting("tool_choice", "auto")}
- **ä¸¦åˆ—å®Ÿè¡Œ**: {"âœ… æœ‰åŠ¹" if tools_config.get_setting("parallel_tool_calls", True) else "âŒ ç„¡åŠ¹"}
- **æœ€å¤§ãƒ„ãƒ¼ãƒ«æ•°/å‘¼ã³å‡ºã—**: {tools_config.get_setting("max_tools_per_call", 5)}
- **Webæ¤œç´¢æœ€å¤§çµæœæ•°**: {tools_config.get_setting("web_search_max_results", 5)}
- **ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢æœ€å¤§ãƒãƒ£ãƒ³ã‚¯æ•°**: {tools_config.get_setting("file_search_max_chunks", 20)}
- **ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—è¡¨ç¤º**: {"âœ… æœ‰åŠ¹" if tools_config.get_setting("show_tool_calls", True) else "âŒ ç„¡åŠ¹"}
- **ãƒ„ãƒ¼ãƒ«çµæœè¡¨ç¤º**: {"âœ… æœ‰åŠ¹" if tools_config.get_setting("show_tool_results", True) else "âŒ ç„¡åŠ¹"}

## ä½¿ç”¨æ–¹æ³•
- `/tools enable [ãƒ„ãƒ¼ãƒ«å]` - ãƒ„ãƒ¼ãƒ«ã‚’æœ‰åŠ¹åŒ–
- `/tools disable [ãƒ„ãƒ¼ãƒ«å]` - ãƒ„ãƒ¼ãƒ«ã‚’ç„¡åŠ¹åŒ–
- `/tools enable all` - ã™ã¹ã¦æœ‰åŠ¹åŒ–
- `/tools disable all` - ã™ã¹ã¦ç„¡åŠ¹åŒ–
"""
    
    await cl.Message(content=tools_message, author="System").send()


async def handle_tools_command(action: str, target: str):
    """Toolsæ©Ÿèƒ½ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å‡¦ç†"""
    if action == "enable":
        if target == "all":
            tools_config.config["enabled"] = True
            for tool_name in tools_config.config.get("tools", {}):
                tools_config.update_tool_status(tool_name, True)
            await cl.Message(
                content="âœ… ã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ«ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ",
                author="System"
            ).send()
        elif target in tools_config.config.get("tools", {}):
            tools_config.config["enabled"] = True
            tools_config.update_tool_status(target, True)
            await cl.Message(
                content=f"âœ… {target}ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ",
                author="System"
            ).send()
        else:
            await cl.Message(
                content=f"âŒ ä¸æ˜ãªãƒ„ãƒ¼ãƒ«: {target}",
                author="System"
            ).send()
    
    elif action == "disable":
        if target == "all":
            tools_config.config["enabled"] = False
            await cl.Message(
                content="âœ… ã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ«ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ",
                author="System"
            ).send()
        elif target in tools_config.config.get("tools", {}):
            tools_config.update_tool_status(target, False)
            await cl.Message(
                content=f"âœ… {target}ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ",
                author="System"
            ).send()
        else:
            await cl.Message(
                content=f"âŒ ä¸æ˜ãªãƒ„ãƒ¼ãƒ«: {target}",
                author="System"
            ).send()
    
    else:
        await cl.Message(
            content=f"âŒ ä¸æ˜ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {action}",
            author="System"
            ).send()


async def change_model(model: str):
    """ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´"""
    valid_models = ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo"]
    
    if model not in valid_models:
        await cl.Message(
            content=f"âŒ ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«åã§ã™ã€‚\nåˆ©ç”¨å¯èƒ½: {', '.join(valid_models)}",
            author="System"
        ).send()
        return
    
    settings = cl.user_session.get("settings", {})
    settings["DEFAULT_MODEL"] = model
    cl.user_session.set("settings", settings)
    
    config_manager.update_setting("DEFAULT_MODEL", model)
    responses_handler.update_model(model)
    
    app_logger.info(f"ãƒ¢ãƒ‡ãƒ«å¤‰æ›´", model=model)
    
    await cl.Message(
        content=f"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ {model} ã«å¤‰æ›´ã—ã¾ã—ãŸ",
        author="System"
    ).send()


async def set_system_prompt(prompt: str):
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š"""
    cl.user_session.set("system_prompt", prompt)
    
    app_logger.info(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š", length=len(prompt))
    
    if prompt:
        await cl.Message(
            content=f"âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®šã—ã¾ã—ãŸ:\n```\n{prompt}\n```",
            author="System"
        ).send()
    else:
        await cl.Message(
            content="âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ",
            author="System"
        ).send()


async def show_statistics():
    """çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
    message_count = cl.user_session.get("message_count", 0)
    total_tokens = cl.user_session.get("total_tokens", 0)
    model = cl.user_session.get("settings", {}).get("DEFAULT_MODEL", "gpt-4o-mini")
    
    stats_message = f"""
# ğŸ“Š ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çµ±è¨ˆ

- **ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°**: {message_count}
- **ä½¿ç”¨ãƒˆãƒ¼ã‚¯ãƒ³**: {total_tokens:,}
- **ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«**: {model}
- **ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: {"è¨­å®šæ¸ˆã¿" if cl.user_session.get("system_prompt") else "æœªè¨­å®š"}
- **ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼**: {data_layer_type or 'æœªè¨­å®š'}
- **Toolsæ©Ÿèƒ½**: {"æœ‰åŠ¹" if tools_config.is_enabled() else "ç„¡åŠ¹"}
  - **æœ‰åŠ¹ãªãƒ„ãƒ¼ãƒ«**: {', '.join(tools_config.get_enabled_tools()) if tools_config.get_enabled_tools() else "ãªã—"}

ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: {"SQLiteãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨ä¸­ã€‚å±¥æ­´ã¯æ°¸ç¶šçš„ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚" if data_layer_type == "SQLite (Persistent)" else "ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ä½¿ç”¨ä¸­ã€‚å±¥æ­´ã¯ã‚¢ãƒ—ãƒªå†èµ·å‹•ã§æ¶ˆå¤±ã—ã¾ã™ã€‚"}
"""
    
    await cl.Message(content=stats_message, author="System").send()


async def start_new_chat():
    """æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹"""
    # ChainlitãŒè‡ªå‹•ã§æ–°ã—ã„ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä½œæˆã™ã‚‹ãŸã‚ã€
    # ã“ã“ã§ã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®ãƒªã‚»ãƒƒãƒˆã®ã¿ã‚’è¡Œã†
    
    app_logger.info("æ–°ã—ã„ãƒãƒ£ãƒƒãƒˆé–‹å§‹")
    
    await cl.Message(
        content=f"""
âœ… æ–°ã—ã„ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã—ãŸ

{"å‰ã®ä¼šè©±ã¯SQLiteã«æ°¸ç¶šçš„ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚" if data_layer_type == "SQLite (Persistent)" else "å‰ã®ä¼šè©±ã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã®ã¿ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚"}
å·¦ä¸Šã®å±¥æ­´ãƒœã‚¿ãƒ³ã‹ã‚‰éå»ã®ä¼šè©±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚
        """,
        author="System"
    ).send()
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã‚’ãƒªã‚»ãƒƒãƒˆ
    cl.user_session.set("message_count", 0)
    cl.user_session.set("total_tokens", 0)
    cl.user_session.set("system_prompt", "")
    cl.user_session.set("previous_response_id", None)
    cl.user_session.set("message_history", [])


async def set_api_key(api_key: str):
    """APIã‚­ãƒ¼ã‚’è¨­å®š"""
    success = config_manager.set_api_key(api_key)
    if success:
        new_settings = config_manager.get_all_settings()
        cl.user_session.set("settings", new_settings)
        responses_handler.update_api_key(api_key)
        
        app_logger.info("APIã‚­ãƒ¼è¨­å®šæˆåŠŸ")
        
        await cl.Message(
            content="âœ… APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¾ã—ãŸ",
            author="System"
        ).send()
        
        await test_connection()


async def test_connection():
    """APIæ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    msg = cl.Message(content="ğŸ”„ æ¥ç¶šãƒ†ã‚¹ãƒˆä¸­...")
    await msg.send()
    
    success, message, models = await config_manager.test_connection()
    
    if success:
        test_success, test_message = await config_manager.test_simple_completion()
        result = f"âœ… æ¥ç¶šæˆåŠŸï¼\n{test_message if test_success else 'å¿œç­”ãƒ†ã‚¹ãƒˆå¤±æ•—'}"
        app_logger.info("APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
    else:
        result = f"âŒ æ¥ç¶šå¤±æ•—: {message}"
        app_logger.error(f"APIæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—", error=message)
    
    await cl.Message(content=result, author="System").send()


async def show_personas():
    """ãƒšãƒ«ã‚½ãƒŠä¸€è¦§ã‚’è¡¨ç¤º"""
    personas = await persona_manager.get_all_personas()
    active_persona = cl.user_session.get("active_persona")
    
    message = "# ğŸ­ ãƒšãƒ«ã‚½ãƒŠä¸€è¦§\n\n"
    
    for persona in personas:
        is_active = active_persona and persona.get("name") == active_persona.get("name")
        status = "âœ… [ã‚¢ã‚¯ãƒ†ã‚£ãƒ–]" if is_active else ""
        
        message += f"## {persona.get('name')} {status}\n"
        message += f"{persona.get('description', 'No description')}\n"
        message += f"- ğŸ¤– Model: {persona.get('model', 'gpt-4o-mini')}\n"
        message += f"- ğŸŒ¡ï¸ Temperature: {persona.get('temperature', 0.7)}\n"
        
        if persona.get('tags'):
            message += f"- ğŸ·ï¸ Tags: {', '.join(persona.get('tags', []))}\n"
        message += "\n"
    
    message += "\nğŸ’¡ **ä½¿ã„æ–¹**: `/persona [ãƒšãƒ«ã‚½ãƒŠå]` ã§åˆ‡ã‚Šæ›¿ãˆ\n"
    message += "ğŸ’¡ **æ–°è¦ä½œæˆ**: `/persona create` ã§æ–°ã—ã„ãƒšãƒ«ã‚½ãƒŠã‚’ä½œæˆ\n"
    message += "ğŸ’¡ **å‰Šé™¤**: `/persona delete [ãƒšãƒ«ã‚½ãƒŠå]` ã§å‰Šé™¤"
    
    await cl.Message(content=message, author="System").send()


async def switch_persona(persona_name: str):
    """ãƒšãƒ«ã‚½ãƒŠã‚’åˆ‡ã‚Šæ›¿ãˆ"""
    personas = await persona_manager.get_all_personas()
    
    # åå‰ã§ãƒšãƒ«ã‚½ãƒŠã‚’æ¤œç´¢
    target_persona = None
    for persona in personas:
        if persona.get("name").lower() == persona_name.lower():
            target_persona = persona
            break
    
    if target_persona:
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«è¨­å®š
        if hasattr(persona_manager, 'set_active_persona'):
            await persona_manager.set_active_persona(target_persona.get("id", target_persona.get("name")))
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’æ›´æ–°
        cl.user_session.set("active_persona", target_persona)
        cl.user_session.set("system_prompt", target_persona.get("system_prompt", ""))
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
        settings = cl.user_session.get("settings", {})
        if target_persona.get("model"):
            settings["DEFAULT_MODEL"] = target_persona.get("model")
            cl.user_session.set("settings", settings)
            
            # responses_handlerã®ãƒ¢ãƒ‡ãƒ«ã‚‚æ›´æ–°
            responses_handler.update_model(target_persona.get("model"))
        
        # è¡¨ç¤º
        info = persona_manager.format_persona_info(target_persona)
        await cl.Message(
            content=f"âœ… ãƒšãƒ«ã‚½ãƒŠã‚’åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ\n\n{info}",
            author="System"
        ).send()
    else:
        await cl.Message(
            content=f"âŒ ãƒšãƒ«ã‚½ãƒŠ '{persona_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`/persona` ã§ä¸€è¦§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
            author="System"
        ).send()


async def create_persona_interactive():
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ãƒšãƒ«ã‚½ãƒŠã‚’ä½œæˆ"""
    # åå‰ã‚’å…¥åŠ›
    res = await cl.AskUserMessage(
        content="ğŸ­ æ–°ã—ã„ãƒšãƒ«ã‚½ãƒŠã®**åå‰**ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
        timeout=60
    ).send()
    
    if not res:
        await cl.Message(content="âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ", author="System").send()
        return
    
    name = res["output"]
    
    # èª¬æ˜ã‚’å…¥åŠ›
    res = await cl.AskUserMessage(
        content="ğŸ“ ãƒšãƒ«ã‚½ãƒŠã®**èª¬æ˜**ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
        timeout=60
    ).send()
    
    if not res:
        await cl.Message(content="âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ", author="System").send()
        return
    
    description = res["output"]
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›
    res = await cl.AskUserMessage(
        content="ğŸ¤– **ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ (AIã®æŒ¯ã‚‹èˆã„ã‚’å®šç¾©):",
        timeout=120
    ).send()
    
    if not res:
        await cl.Message(content="âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ", author="System").send()
        return
    
    system_prompt = res["output"]
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
    models_list = "\n".join([f"- {model}" for model in persona_manager.AVAILABLE_MODELS])
    res = await cl.AskUserMessage(
        content=f"ğŸ¤– ä½¿ç”¨ã™ã‚‹**ãƒ¢ãƒ‡ãƒ«**ã‚’é¸æŠã—ã¦ãã ã•ã„:\n{models_list}\n\n(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gpt-4o-mini)",
        timeout=60
    ).send()
    
    model = "gpt-4o-mini"
    if res:
        input_model = res["output"].strip()
        if input_model in persona_manager.AVAILABLE_MODELS:
            model = input_model
    
    # Temperatureã‚’å…¥åŠ›
    res = await cl.AskUserMessage(
        content="ğŸŒ¡ï¸ **Temperature** (0.0-2.0, ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.7)\nä½ã„å€¤=ã‚ˆã‚Šä¸€è²«æ€§ãŒã‚ã‚‹ã€é«˜ã„å€¤=ã‚ˆã‚Šå‰µé€ çš„:",
        timeout=60
    ).send()
    
    temperature = 0.7
    if res:
        try:
            temp_value = float(res["output"])
            if 0.0 <= temp_value <= 2.0:
                temperature = temp_value
        except ValueError:
            pass
    
    # ã‚¿ã‚°ã‚’å…¥åŠ›
    res = await cl.AskUserMessage(
        content="ğŸ·ï¸ **ã‚¿ã‚°** (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€ä¾‹: technical, creative, business):",
        timeout=60
    ).send()
    
    tags = []
    if res:
        tags = [tag.strip() for tag in res["output"].split(",") if tag.strip()]
    
    # ãƒšãƒ«ã‚½ãƒŠã‚’ä½œæˆ
    persona_data = {
        "name": name,
        "description": description,
        "system_prompt": system_prompt,
        "model": model,
        "temperature": temperature,
        "tags": tags
    }
    
    persona_id = await persona_manager.create_persona(persona_data)
    
    # ç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    info = persona_manager.format_persona_info(persona_data)
    await cl.Message(
        content=f"âœ… ãƒšãƒ«ã‚½ãƒŠã‚’ä½œæˆã—ã¾ã—ãŸ\n\n{info}\n\n`/persona {name}` ã§åˆ‡ã‚Šæ›¿ãˆã§ãã¾ã™ã€‚",
        author="System"
    ).send()


async def delete_persona(persona_name: str):
    """ãƒšãƒ«ã‚½ãƒŠã‚’å‰Šé™¤"""
    personas = await persona_manager.get_all_personas()
    
    # åå‰ã§ãƒšãƒ«ã‚½ãƒŠã‚’æ¤œç´¢
    target_persona = None
    for persona in personas:
        if persona.get("name").lower() == persona_name.lower():
            target_persona = persona
            break
    
    if target_persona:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒšãƒ«ã‚½ãƒŠã¯å‰Šé™¤ã§ããªã„
        if target_persona.get("name") in ["æ±ç”¨ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€å®¶", "ãƒ“ã‚¸ãƒã‚¹ã‚¢ãƒŠãƒªã‚¹ãƒˆ", "ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãƒ©ã‚¤ã‚¿ãƒ¼", "å­¦ç¿’ã‚µãƒãƒ¼ã‚¿ãƒ¼"]:
            await cl.Message(
                content="âŒ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒšãƒ«ã‚½ãƒŠã¯å‰Šé™¤ã§ãã¾ã›ã‚“ã€‚",
                author="System"
            ).send()
            return
        
        # å‰Šé™¤å®Ÿè¡Œ
        success = await persona_manager.delete_persona(target_persona.get("id", target_persona.get("name")))
        
        if success:
            await cl.Message(
                content=f"âœ… ãƒšãƒ«ã‚½ãƒŠ '{persona_name}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚",
                author="System"
            ).send()
        else:
            await cl.Message(
                content=f"âŒ ãƒšãƒ«ã‚½ãƒŠ '{persona_name}' ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚",
                author="System"
            ).send()
    else:
        await cl.Message(
            content=f"âŒ ãƒšãƒ«ã‚½ãƒŠ '{persona_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚",
            author="System"
        ).send()


async def show_status():
    """è¨­å®šçŠ¶æ…‹ã‚’è¡¨ç¤º"""
    settings = config_manager.get_all_settings()
    
    status_message = f"""
## ğŸ“Š ç¾åœ¨ã®è¨­å®š

- **APIã‚­ãƒ¼**: {settings.get('OPENAI_API_KEY_DISPLAY', 'æœªè¨­å®š')}
- **ãƒ¢ãƒ‡ãƒ«**: {cl.user_session.get('settings', {}).get('DEFAULT_MODEL', 'gpt-4o-mini')}
- **ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°**: {cl.user_session.get("message_count", 0)}
- **ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡**: {cl.user_session.get("total_tokens", 0):,}
- **ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: {"è¨­å®šæ¸ˆã¿" if cl.user_session.get("system_prompt") else "æœªè¨­å®š"}
- **ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼**: {data_layer_type or 'æœªè¨­å®š'}
- **Toolsæ©Ÿèƒ½**: {"æœ‰åŠ¹" if tools_config.is_enabled() else "ç„¡åŠ¹"}
"""
    
    await cl.Message(content=status_message, author="System").send()


if __name__ == "__main__":
    app_logger.info(f"Starting {APP_NAME} {VERSION}")
    app_logger.info(f"Working Directory: {os.getcwd()}")
    
    print(f"Starting {APP_NAME} {VERSION}")
    print(f"Working Directory: {os.getcwd()}")
    print("=" * 50)
    print("ğŸ“Œ ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®çŠ¶æ…‹:")
    print(f"   - ã‚¿ã‚¤ãƒ—: {data_layer_type or 'æœªè¨­å®š'}")
    if data_layer_type == "SQLite (Persistent)":
        print("   âœ… SQLite: å±¥æ­´ã¯æ°¸ç¶šçš„ã«ä¿å­˜ã•ã‚Œã¾ã™")
        print("   ğŸ“‚ ä¿å­˜å ´æ‰€: .chainlit/chainlit.db")
    elif data_layer_type == "Simple In-Memory":
        print("   âš ï¸ ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒª: å±¥æ­´ã¯ã‚¢ãƒ—ãƒªå†èµ·å‹•ã§æ¶ˆå¤±ã—ã¾ã™")
    elif not data_layer_type:
        print("   âŒ ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("   ğŸ“ å±¥æ­´æ©Ÿèƒ½ãŒå‹•ä½œã—ã¾ã›ã‚“")
    print("=" * 50)
    print("ğŸ“Œ Toolsæ©Ÿèƒ½ã®çŠ¶æ…‹:")
    print(f"   - å…¨ä½“: {'æœ‰åŠ¹' if tools_config.is_enabled() else 'ç„¡åŠ¹'}")
    if tools_config.is_enabled():
        enabled_tools = tools_config.get_enabled_tools()
        print(f"   - æœ‰åŠ¹ãªãƒ„ãƒ¼ãƒ«: {', '.join(enabled_tools) if enabled_tools else 'ãªã—'}")
    print("=" * 50)
    print("ğŸ“Œ ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±:")
    print("   - ãƒ¦ãƒ¼ã‚¶ãƒ¼å: admin")
    print("   - ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰: admin123 (ã¾ãŸã¯.envã§è¨­å®šã—ãŸå€¤)")
    print("=" * 50)
    
    current_settings = config_manager.get_all_settings()
    print(f"API Key: {current_settings.get('OPENAI_API_KEY_DISPLAY', 'Not set')}")
    print(f"Default Model: {current_settings.get('DEFAULT_MODEL', 'Not set')}")
    
    app_logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•å®Œäº†")
