"""
OpenAI Chat Completions APIç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
- Chat Completions APIã®å‘¼ã³å‡ºã—
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”å‡¦ç†
- Tools/Function callingå¯¾å¿œ
- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ç®¡ç†
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
"""

import os
import json
from typing import Dict, List, Optional, AsyncGenerator, Any, Union
from openai import OpenAI, AsyncOpenAI
import httpx
from datetime import datetime
import asyncio


class ResponseHandler:
    """OpenAI Chat Completions APIç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.api_key = os.getenv("OPENAI_API_KEY", "")
        self.default_model = os.getenv("DEFAULT_MODEL", "gpt-4o-mini")
        self.client = None
        self.async_client = None
        self._init_clients()
    
    def _init_clients(self):
        """OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        if not self.api_key or self.api_key == "your_api_key_here":
            return
        
        # ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã‚’ç¢ºèª
        http_proxy = os.getenv("HTTP_PROXY", "")
        https_proxy = os.getenv("HTTPS_PROXY", "")
        
        http_client = None
        if http_proxy or https_proxy:
            proxies = {}
            if http_proxy:
                proxies["http://"] = http_proxy
            if https_proxy:
                proxies["https://"] = https_proxy
            http_client = httpx.Client(proxies=proxies)
        
        # åŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        self.client = OpenAI(
            api_key=self.api_key,
            http_client=http_client
        )
        
        # éåŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        async_http_client = None
        if http_proxy or https_proxy:
            async_http_client = httpx.AsyncClient(proxies=proxies)
        
        self.async_client = AsyncOpenAI(
            api_key=self.api_key,
            http_client=async_http_client
        )
    
    def update_api_key(self, api_key: str):
        """APIã‚­ãƒ¼ã‚’æ›´æ–°"""
        self.api_key = api_key
        os.environ["OPENAI_API_KEY"] = api_key
        self._init_clients()
    
    def update_model(self, model: str):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°"""
        self.default_model = model
        os.environ["DEFAULT_MODEL"] = model
    
    async def create_chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = None,
        temperature: float = 0.7,
        max_tokens: int = None,
        stream: bool = True,
        tools: List[Dict] = None,
        tool_choice: Union[str, Dict] = None,
        **kwargs
    ) -> AsyncGenerator[Dict, None]:
        """
        Chat Completions APIã‚’å‘¼ã³å‡ºã—ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã€Toolså¯¾å¿œï¼‰
        
        Args:
            messages: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´
            model: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«
            temperature: å‰µé€ æ€§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            stream: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æœ‰åŠ¹/ç„¡åŠ¹
            tools: ä½¿ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«å®šç¾©
            tool_choice: ãƒ„ãƒ¼ãƒ«é¸æŠè¨­å®š
            **kwargs: ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
        Yields:
            ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒ£ãƒ³ã‚¯ or å®Œäº†ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        """
        if not self.async_client:
            yield {
                "error": "APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
                "type": "configuration_error"
            }
            return
        
        model = model or self.default_model
        
        # APIå‘¼ã³å‡ºã—ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
        api_params = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "stream": stream,
            **kwargs
        }
        
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        if max_tokens:
            api_params["max_tokens"] = max_tokens
        if tools:
            api_params["tools"] = tools
        if tool_choice:
            api_params["tool_choice"] = tool_choice
        
        try:
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
            if stream:
                response = await self.async_client.chat.completions.create(**api_params)
                
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†
                async for chunk in response:
                    # ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªã«å¤‰æ›
                    chunk_dict = {
                        "id": chunk.id,
                        "model": chunk.model,
                        "created": chunk.created,
                        "choices": []
                    }
                    
                    # choices ã‚’å‡¦ç†
                    if chunk.choices:
                        for choice in chunk.choices:
                            choice_dict = {
                                "index": choice.index,
                                "delta": {}
                            }
                            
                            # deltaã®å†…å®¹ã‚’å‡¦ç†
                            if choice.delta:
                                if choice.delta.content is not None:
                                    choice_dict["delta"]["content"] = choice.delta.content
                                if choice.delta.role is not None:
                                    choice_dict["delta"]["role"] = choice.delta.role
                                if hasattr(choice.delta, 'tool_calls') and choice.delta.tool_calls:
                                    choice_dict["delta"]["tool_calls"] = [
                                        {
                                            "index": tc.index,
                                            "id": tc.id if hasattr(tc, 'id') else None,
                                            "type": tc.type if hasattr(tc, 'type') else None,
                                            "function": {
                                                "name": tc.function.name if hasattr(tc.function, 'name') else None,
                                                "arguments": tc.function.arguments if hasattr(tc.function, 'arguments') else None
                                            } if hasattr(tc, 'function') else None
                                        } for tc in choice.delta.tool_calls
                                    ]
                            
                            # finish_reasonã‚’å‡¦ç†
                            if choice.finish_reason:
                                choice_dict["finish_reason"] = choice.finish_reason
                            
                            chunk_dict["choices"].append(choice_dict)
                    
                    # usageæƒ…å ±ãŒã‚ã‚Œã°è¿½åŠ 
                    if hasattr(chunk, 'usage') and chunk.usage:
                        chunk_dict["usage"] = {
                            "prompt_tokens": chunk.usage.prompt_tokens,
                            "completion_tokens": chunk.usage.completion_tokens,
                            "total_tokens": chunk.usage.total_tokens
                        }
                    
                    yield chunk_dict
            
            # éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
            else:
                response = await self.async_client.chat.completions.create(**api_params)
                
                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªã«å¤‰æ›
                response_dict = {
                    "id": response.id,
                    "model": response.model,
                    "created": response.created,
                    "choices": [],
                    "usage": {
                        "prompt_tokens": response.usage.prompt_tokens,
                        "completion_tokens": response.usage.completion_tokens,
                        "total_tokens": response.usage.total_tokens
                    }
                }
                
                # choicesã‚’å‡¦ç†
                for choice in response.choices:
                    choice_dict = {
                        "index": choice.index,
                        "message": {
                            "role": choice.message.role,
                            "content": choice.message.content
                        },
                        "finish_reason": choice.finish_reason
                    }
                    
                    # tool_callsãŒã‚ã‚‹å ´åˆ
                    if hasattr(choice.message, 'tool_calls') and choice.message.tool_calls:
                        choice_dict["message"]["tool_calls"] = [
                            {
                                "id": tc.id,
                                "type": tc.type,
                                "function": {
                                    "name": tc.function.name,
                                    "arguments": tc.function.arguments
                                }
                            } for tc in choice.message.tool_calls
                        ]
                    
                    response_dict["choices"].append(choice_dict)
                
                yield response_dict
        
        except Exception as e:
            yield {
                "error": str(e),
                "type": "api_error"
            }
    
    async def create_chat_completion_with_tools(
        self,
        messages: List[Dict[str, Any]],
        tools: List[Dict[str, Any]],
        model: str = None,
        **kwargs
    ) -> AsyncGenerator[Dict, None]:
        """
        Tools/Function callingã‚’ä½¿ç”¨ã—ãŸChat Completions APIå‘¼ã³å‡ºã—
        
        Args:
            messages: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´
            tools: ãƒ„ãƒ¼ãƒ«å®šç¾©ã®ãƒªã‚¹ãƒˆ
            model: ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«
            **kwargs: ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
        Yields:
            APIå¿œç­”
        """
        async for chunk in self.create_chat_completion(
            messages=messages,
            model=model,
            tools=tools,
            tool_choice="auto",
            **kwargs
        ):
            yield chunk
    
    def format_messages_for_api(
        self,
        messages: List[Dict[str, Any]],
        system_prompt: str = None
    ) -> List[Dict[str, str]]:
        """
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’APIç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        
        Args:
            messages: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—ã—ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            system_prompt: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        
        Returns:
            APIç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ
        """
        formatted = []
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
        if system_prompt:
            formatted.append({
                "role": "system",
                "content": system_prompt
            })
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’å¤‰æ›
        for msg in messages:
            formatted.append({
                "role": msg.get("role", "user"),
                "content": msg.get("content", "")
            })
        
        return formatted
    
    def calculate_token_estimate(self, text: str) -> int:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®š
        
        Args:
            text: ãƒ†ã‚­ã‚¹ãƒˆ
        
        Returns:
            æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        # ç°¡æ˜“çš„ãªæ¨å®šï¼ˆå®Ÿéš›ã¯tiktokenã‚’ä½¿ã†ã¹ãï¼‰
        # æ—¥æœ¬èª: 1æ–‡å­— â‰ˆ 2-3ãƒˆãƒ¼ã‚¯ãƒ³
        # è‹±èª: 1å˜èª â‰ˆ 1-1.5ãƒˆãƒ¼ã‚¯ãƒ³
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«æ–‡å­—æ•°ã®1/3ã¨ã—ã¦æ¨å®š
        return len(text) // 3
    
    async def generate_title(self, messages: List[Dict[str, str]]) -> str:
        """
        ä¼šè©±ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’è‡ªå‹•ç”Ÿæˆ
        
        Args:
            messages: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´
        
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«
        """
        if not self.async_client:
            return f"Chat - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        
        try:
            # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            title_prompt = [
                {"role": "system", "content": "ä»¥ä¸‹ã®ä¼šè©±ã‹ã‚‰ã€çŸ­ãç°¡æ½”ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’æ—¥æœ¬èªã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚20æ–‡å­—ä»¥å†…ã§ã€‚"},
                *messages[:3]  # æœ€åˆã®3ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ä½¿ç”¨
            ]
            
            response = await self.async_client.chat.completions.create(
                model="gpt-4o-mini",  # é«˜é€Ÿãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
                messages=title_prompt,
                temperature=0.5,
                max_tokens=30,
                stream=False
            )
            
            title = response.choices[0].message.content.strip()
            # ã‚¿ã‚¤ãƒˆãƒ«ãŒé•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚
            if len(title) > 30:
                title = title[:27] + "..."
            
            return title
        
        except Exception as e:
            print(f"Error generating title: {e}")
            return f"Chat - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
    
    def extract_code_blocks(self, text: str) -> List[Dict[str, str]]:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡º
        
        Args:
            text: ãƒ†ã‚­ã‚¹ãƒˆ
        
        Returns:
            ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒªã‚¹ãƒˆ [{language: str, code: str}]
        """
        import re
        
        pattern = r'```(\w+)?\n(.*?)```'
        matches = re.findall(pattern, text, re.DOTALL)
        
        code_blocks = []
        for match in matches:
            language = match[0] or "plaintext"
            code = match[1].strip()
            code_blocks.append({
                "language": language,
                "code": code
            })
        
        return code_blocks
    
    def format_token_usage(self, usage: Dict[str, int]) -> str:
        """
        ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        
        Args:
            usage: ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡
        
        Returns:
            ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸæ–‡å­—åˆ—
        """
        if not usage:
            return ""
        
        prompt = usage.get("prompt_tokens", 0)
        completion = usage.get("completion_tokens", 0)
        total = usage.get("total_tokens", 0)
        
        # æ¦‚ç®—ã‚³ã‚¹ãƒˆè¨ˆç®—ï¼ˆGPT-4o-miniã®æ–™é‡‘: $0.15/1M input, $0.6/1M outputï¼‰
        input_cost = prompt * 0.00000015
        output_cost = completion * 0.0000006
        total_cost = input_cost + output_cost
        
        return f"ğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡: å…¥åŠ› {prompt} + å‡ºåŠ› {completion} = åˆè¨ˆ {total} (ç´„${total_cost:.4f})"
    
    # Tools/Function callingç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
    def create_tool_definition(
        self,
        name: str,
        description: str,
        parameters: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ãƒ„ãƒ¼ãƒ«å®šç¾©ã‚’ä½œæˆ
        
        Args:
            name: ãƒ„ãƒ¼ãƒ«å
            description: ãƒ„ãƒ¼ãƒ«ã®èª¬æ˜
            parameters: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚¹ã‚­ãƒ¼ãƒ
        
        Returns:
            ãƒ„ãƒ¼ãƒ«å®šç¾©
        """
        return {
            "type": "function",
            "function": {
                "name": name,
                "description": description,
                "parameters": parameters
            }
        }
    
    def parse_tool_call(self, tool_call: Dict[str, Any]) -> Dict[str, Any]:
        """
        ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’ãƒ‘ãƒ¼ã‚¹
        
        Args:
            tool_call: ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        
        Returns:
            ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸçµæœ
        """
        return {
            "id": tool_call.get("id"),
            "type": tool_call.get("type"),
            "function_name": tool_call.get("function", {}).get("name"),
            "arguments": json.loads(tool_call.get("function", {}).get("arguments", "{}"))
        }
    
    def create_tool_response_message(
        self,
        tool_call_id: str,
        content: str
    ) -> Dict[str, Any]:
        """
        ãƒ„ãƒ¼ãƒ«å¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
        
        Args:
            tool_call_id: ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ID
            content: ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œçµæœ
        
        Returns:
            ãƒ„ãƒ¼ãƒ«å¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        return {
            "role": "tool",
            "content": content,
            "tool_call_id": tool_call_id
        }


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
response_handler = ResponseHandler()
