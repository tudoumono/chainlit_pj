"""
é«˜åº¦æ¤œç´¢æ©Ÿèƒ½ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
ä¼šè©±å±¥æ­´ã€ãƒšãƒ«ã‚½ãƒŠã€ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®æ¨ªæ–­æ¤œç´¢æ©Ÿèƒ½
"""

import sqlite3
import json
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from utils.ui_helper import ChainlitHelper as ui
from utils.error_handler import ErrorHandler as error_handler  
from utils.logger import app_logger
from utils.persona_manager import persona_manager
from utils.vector_store_handler import vector_store_handler


@dataclass
class SearchResult:
    """æ¤œç´¢çµæœã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    result_type: str  # "conversation", "persona", "vector_store"
    title: str
    content: str
    metadata: Dict[str, Any]
    relevance_score: float
    timestamp: Optional[str] = None
    
    
@dataclass
class SearchFilters:
    """æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    persona_names: Optional[List[str]] = None
    models: Optional[List[str]] = None
    result_types: Optional[List[str]] = None
    min_relevance: float = 0.0


class SearchHandler:
    """é«˜åº¦æ¤œç´¢æ©Ÿèƒ½ã‚’çµ±æ‹¬ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        """æ¤œç´¢ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–"""
        self.chainlit_db_path = ".chainlit/chainlit.db"
        self.analytics_db_path = ".chainlit/analytics.db"
        
    async def search_all(
        self,
        query: str,
        user_id: str = None,
        filters: SearchFilters = None,
        limit: int = 20
    ) -> List[SearchResult]:
        """å…¨ãƒ‡ãƒ¼ã‚¿æ¨ªæ–­æ¤œç´¢"""
        try:
            if not query.strip():
                await ui.send_error_message("æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                return []
            
            app_logger.info("æ¨ªæ–­æ¤œç´¢é–‹å§‹", query=query, user_id=user_id)
            
            filters = filters or SearchFilters()
            results = []
            
            # ä¼šè©±å±¥æ­´ã®æ¤œç´¢
            if not filters.result_types or "conversation" in filters.result_types:
                conversation_results = await self._search_conversations(query, user_id, filters)
                results.extend(conversation_results)
            
            # ãƒšãƒ«ã‚½ãƒŠã®æ¤œç´¢
            if not filters.result_types or "persona" in filters.result_types:
                persona_results = await self._search_personas(query)
                results.extend(persona_results)
            
            # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®æ¤œç´¢
            if not filters.result_types or "vector_store" in filters.result_types:
                vs_results = await self._search_vector_stores(query, user_id)
                results.extend(vs_results)
            
            # é–¢é€£åº¦é †ã«ã‚½ãƒ¼ãƒˆ
            results.sort(key=lambda r: r.relevance_score, reverse=True)
            
            # æœ€å°é–¢é€£åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
            results = [r for r in results if r.relevance_score >= filters.min_relevance]
            
            app_logger.info("æ¨ªæ–­æ¤œç´¢å®Œäº†", results_count=len(results))
            return results[:limit]
            
        except Exception as e:
            await error_handler.handle_unexpected_error(e, "æ¨ªæ–­æ¤œç´¢")
            return []
    
    async def show_search_results(self, results: List[SearchResult], query: str):
        """æ¤œç´¢çµæœã‚’æ•´å½¢ã—ã¦è¡¨ç¤º"""
        try:
            if not results:
                await ui.send_info_message(
                    f"ğŸ” æ¤œç´¢çµæœ\n\n"
                    f"ã‚¯ã‚¨ãƒª: **{query}**\n"
                    f"çµæœ: è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                )
                return
            
            message = f"# ğŸ” æ¤œç´¢çµæœ\n\n"
            message += f"**ã‚¯ã‚¨ãƒª**: {query}\n"
            message += f"**ä»¶æ•°**: {len(results)}ä»¶\n\n"
            
            # çµæœã‚¿ã‚¤ãƒ—åˆ¥ã«åˆ†é¡
            conversation_results = [r for r in results if r.result_type == "conversation"]
            persona_results = [r for r in results if r.result_type == "persona"]
            vs_results = [r for r in results if r.result_type == "vector_store"]
            
            # ä¼šè©±å±¥æ­´ã®çµæœ
            if conversation_results:
                message += f"## ğŸ’¬ ä¼šè©±å±¥æ­´ ({len(conversation_results)}ä»¶)\n\n"
                for i, result in enumerate(conversation_results[:5], 1):
                    highlighted_content = self._highlight_query_in_text(result.content, query)
                    timestamp = result.timestamp[:16] if result.timestamp else "ä¸æ˜"
                    
                    message += f"### {i}. {result.title}\n"
                    message += f"**æ—¥æ™‚**: {timestamp}\n"
                    message += f"**é–¢é€£åº¦**: {result.relevance_score:.2f}\n"
                    message += f"**å†…å®¹**: {highlighted_content[:200]}{'...' if len(result.content) > 200 else ''}\n"
                    
                    if result.metadata:
                        if result.metadata.get("persona"):
                            message += f"**ãƒšãƒ«ã‚½ãƒŠ**: {result.metadata['persona']}\n"
                        if result.metadata.get("model"):
                            message += f"**ãƒ¢ãƒ‡ãƒ«**: {result.metadata['model']}\n"
                    
                    message += "\n"
                
                if len(conversation_results) > 5:
                    message += f"*ä»–{len(conversation_results) - 5}ä»¶ã®ä¼šè©±çµæœãŒã‚ã‚Šã¾ã™*\n\n"
            
            # ãƒšãƒ«ã‚½ãƒŠã®çµæœ
            if persona_results:
                message += f"## ğŸ­ ãƒšãƒ«ã‚½ãƒŠ ({len(persona_results)}ä»¶)\n\n"
                for i, result in enumerate(persona_results, 1):
                    highlighted_content = self._highlight_query_in_text(result.content, query)
                    
                    message += f"### {i}. {result.title}\n"
                    message += f"**é–¢é€£åº¦**: {result.relevance_score:.2f}\n"
                    message += f"**èª¬æ˜**: {highlighted_content}\n"
                    
                    if result.metadata:
                        if result.metadata.get("model"):
                            message += f"**ãƒ¢ãƒ‡ãƒ«**: {result.metadata['model']}\n"
                        if result.metadata.get("tags"):
                            message += f"**ã‚¿ã‚°**: {', '.join(result.metadata['tags'])}\n"
                    
                    message += "\n"
            
            # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®çµæœ
            if vs_results:
                message += f"## ğŸ—‚ï¸ ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ ({len(vs_results)}ä»¶)\n\n"
                for i, result in enumerate(vs_results, 1):
                    message += f"### {i}. {result.title}\n"
                    message += f"**é–¢é€£åº¦**: {result.relevance_score:.2f}\n"
                    message += f"**ã‚¿ã‚¤ãƒ—**: {result.metadata.get('vs_type', 'Unknown')}\n"
                    
                    if result.content:
                        highlighted_content = self._highlight_query_in_text(result.content, query)
                        message += f"**å†…å®¹**: {highlighted_content[:150]}{'...' if len(result.content) > 150 else ''}\n"
                    
                    message += "\n"
            
            await ui.send_system_message(message)
            
        except Exception as e:
            await error_handler.handle_unexpected_error(e, "æ¤œç´¢çµæœè¡¨ç¤º")
    
    async def advanced_search_with_filters(
        self,
        query: str,
        user_id: str = None,
        start_date: str = None,
        end_date: str = None,
        persona_names: List[str] = None,
        models: List[str] = None,
        result_types: List[str] = None
    ):
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ä»˜ãé«˜åº¦æ¤œç´¢"""
        try:
            loading_msg = await ui.show_loading_message("é«˜åº¦æ¤œç´¢ã‚’å®Ÿè¡Œä¸­...")
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ§‹ç¯‰
            filters = SearchFilters(
                start_date=start_date,
                end_date=end_date,
                persona_names=persona_names,
                models=models,
                result_types=result_types,
                min_relevance=0.1
            )
            
            # æ¤œç´¢å®Ÿè¡Œ
            results = await self.search_all(query, user_id, filters)
            
            await ui.update_loading_message(loading_msg, "æ¤œç´¢çµæœã‚’æ•´ç†ä¸­...")
            
            # çµæœè¡¨ç¤º
            await self.show_search_results(results, query)
            
            # æ¤œç´¢çµ±è¨ˆ
            stats_message = self._generate_search_stats(results, filters)
            if stats_message:
                await ui.send_system_message(stats_message)
            
        except Exception as e:
            await error_handler.handle_unexpected_error(e, "é«˜åº¦æ¤œç´¢")
    
    async def search_conversations_only(
        self,
        query: str,
        user_id: str = None,
        limit: int = 10
    ):
        """ä¼šè©±å±¥æ­´ã®ã¿ã‚’æ¤œç´¢"""
        try:
            loading_msg = await ui.show_loading_message("ä¼šè©±å±¥æ­´ã‚’æ¤œç´¢ä¸­...")
            
            results = await self._search_conversations(query, user_id, SearchFilters())
            results = results[:limit]
            
            if not results:
                await ui.update_loading_message(
                    loading_msg,
                    f"ğŸ” ä¼šè©±å±¥æ­´æ¤œç´¢çµæœ\n\n"
                    f"ã‚¯ã‚¨ãƒª: **{query}**\n"
                    f"è©²å½“ã™ã‚‹ä¼šè©±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                )
                return
            
            message = f"# ğŸ’¬ ä¼šè©±å±¥æ­´æ¤œç´¢çµæœ\n\n"
            message += f"**ã‚¯ã‚¨ãƒª**: {query}\n"
            message += f"**ä»¶æ•°**: {len(results)}ä»¶\n\n"
            
            for i, result in enumerate(results, 1):
                highlighted_content = self._highlight_query_in_text(result.content, query)
                timestamp = result.timestamp[:16] if result.timestamp else "ä¸æ˜"
                
                message += f"## {i}. {result.title}\n"
                message += f"**æ—¥æ™‚**: {timestamp}\n"
                message += f"**é–¢é€£åº¦**: {result.relevance_score:.2f}\n\n"
                message += f"{highlighted_content[:300]}{'...' if len(result.content) > 300 else ''}\n\n"
                
                if result.metadata:
                    details = []
                    if result.metadata.get("persona"):
                        details.append(f"ãƒšãƒ«ã‚½ãƒŠ: {result.metadata['persona']}")
                    if result.metadata.get("model"):
                        details.append(f"ãƒ¢ãƒ‡ãƒ«: {result.metadata['model']}")
                    if details:
                        message += f"*{' | '.join(details)}*\n\n"
                
                message += "---\n\n"
            
            await ui.update_loading_message(loading_msg, message)
            
        except Exception as e:
            await error_handler.handle_unexpected_error(e, "ä¼šè©±å±¥æ­´æ¤œç´¢")
    
    async def _search_conversations(
        self,
        query: str,
        user_id: str = None,
        filters: SearchFilters = None
    ) -> List[SearchResult]:
        """ä¼šè©±å±¥æ­´ã‚’æ¤œç´¢"""
        try:
            results = []
            
            with sqlite3.connect(self.chainlit_db_path) as conn:
                cursor = conn.cursor()
                
                # åŸºæœ¬çš„ãªSQLã‚¯ã‚¨ãƒª
                sql = """
                SELECT e.id, e.type, e.content, e.created_at, s.id as session_id, s.metadata
                FROM element e
                LEFT JOIN step s ON e.step_id = s.id
                WHERE e.content IS NOT NULL 
                AND e.content != ''
                AND e.content LIKE ?
                """
                params = [f"%{query}%"]
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                if user_id:
                    sql += " AND s.user_id = ?"
                    params.append(user_id)
                
                # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                if filters and filters.start_date:
                    sql += " AND e.created_at >= ?"
                    params.append(filters.start_date)
                
                if filters and filters.end_date:
                    sql += " AND e.created_at <= ?"
                    params.append(filters.end_date)
                
                sql += " ORDER BY e.created_at DESC LIMIT 50"
                
                cursor.execute(sql, params)
                rows = cursor.fetchall()
                
                for row in rows:
                    element_id, element_type, content, created_at, session_id, session_metadata = row
                    
                    # é–¢é€£åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
                    relevance_score = self._calculate_text_relevance(content, query)
                    
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è§£æ
                    metadata = {}
                    if session_metadata:
                        try:
                            parsed_metadata = json.loads(session_metadata)
                            metadata = {
                                "persona": parsed_metadata.get("active_persona", {}).get("name"),
                                "model": parsed_metadata.get("model"),
                                "session_id": session_id
                            }
                        except (json.JSONDecodeError, AttributeError):
                            pass
                    
                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
                    if filters:
                        if filters.persona_names and metadata.get("persona") not in filters.persona_names:
                            continue
                        if filters.models and metadata.get("model") not in filters.models:
                            continue
                    
                    result = SearchResult(
                        result_type="conversation",
                        title=f"ä¼šè©± #{element_id}",
                        content=content,
                        metadata=metadata,
                        relevance_score=relevance_score,
                        timestamp=created_at
                    )
                    
                    results.append(result)
            
            return results
            
        except Exception as e:
            app_logger.error(f"ä¼šè©±å±¥æ­´æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def _search_personas(self, query: str) -> List[SearchResult]:
        """ãƒšãƒ«ã‚½ãƒŠã‚’æ¤œç´¢"""
        try:
            results = []
            personas = await persona_manager.get_all_personas()
            
            for persona in personas:
                # åå‰ã¨èª¬æ˜ã§æ¤œç´¢
                searchable_text = f"{persona.get('name', '')} {persona.get('description', '')} {persona.get('system_prompt', '')}"
                
                relevance_score = self._calculate_text_relevance(searchable_text, query)
                
                if relevance_score > 0.1:  # æœ€å°é–¢é€£åº¦ãƒã‚§ãƒƒã‚¯
                    result = SearchResult(
                        result_type="persona",
                        title=persona.get("name", "Unknown Persona"),
                        content=persona.get("description", ""),
                        metadata={
                            "model": persona.get("model"),
                            "temperature": persona.get("temperature"),
                            "tags": persona.get("tags", [])
                        },
                        relevance_score=relevance_score
                    )
                    results.append(result)
            
            return results
            
        except Exception as e:
            app_logger.error(f"ãƒšãƒ«ã‚½ãƒŠæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def _search_vector_stores(self, query: str, user_id: str = None) -> List[SearchResult]:
        """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’æ¤œç´¢"""
        try:
            results = []
            
            # åˆ©ç”¨å¯èƒ½ãªãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢IDã‚’å–å¾—
            vs_ids = []
            
            # Company VS
            company_vs_id = os.environ.get("COMPANY_VECTOR_STORE_ID")
            if company_vs_id:
                vs_ids.append(("company", company_vs_id))
            
            # Personal VS (ç°¡æ˜“å®Ÿè£… - å®Ÿéš›ã¯data_layerã‹ã‚‰å–å¾—)
            # TODO: data_layerã¨ã®é€£æºå®Ÿè£…
            
            for vs_type, vs_id in vs_ids:
                try:
                    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢æƒ…å ±ã‚’å–å¾—
                    vs_info = await vector_store_handler.get_vector_store_info(vs_id)
                    
                    if vs_info:
                        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢åã§ã®æ¤œç´¢
                        searchable_text = f"{vs_info.get('name', '')} {vs_type}"
                        relevance_score = self._calculate_text_relevance(searchable_text, query)
                        
                        if relevance_score > 0.1:
                            result = SearchResult(
                                result_type="vector_store",
                                title=vs_info.get("name", f"Vector Store {vs_id[:8]}"),
                                content=f"ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ ({vs_type})",
                                metadata={
                                    "vs_type": vs_type,
                                    "vs_id": vs_id,
                                    "file_count": vs_info.get("file_counts", {}).get("total", 0)
                                },
                                relevance_score=relevance_score
                            )
                            results.append(result)
                            
                except Exception as e:
                    app_logger.warning(f"ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ {vs_id} æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            return results
            
        except Exception as e:
            app_logger.error(f"ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _calculate_text_relevance(self, text: str, query: str) -> float:
        """ãƒ†ã‚­ã‚¹ãƒˆã®é–¢é€£åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        if not text or not query:
            return 0.0
        
        text_lower = text.lower()
        query_lower = query.lower()
        query_words = query_lower.split()
        
        score = 0.0
        
        # å®Œå…¨ä¸€è‡´
        if query_lower in text_lower:
            score += 1.0
        
        # å˜èªåˆ¥ãƒãƒƒãƒãƒ³ã‚°
        matched_words = 0
        for word in query_words:
            if word in text_lower:
                matched_words += 1
        
        word_match_ratio = matched_words / len(query_words) if query_words else 0
        score += word_match_ratio * 0.8
        
        # å˜èªã®è¿‘æ¥æ€§ (ç°¡æ˜“å®Ÿè£…)
        if len(query_words) > 1:
            for i, word1 in enumerate(query_words[:-1]):
                word2 = query_words[i + 1]
                # 50æ–‡å­—ä»¥å†…ã§é€£ç¶šã™ã‚‹å˜èªãŒã‚ã‚Œã°ãƒœãƒ¼ãƒŠã‚¹
                word1_pos = text_lower.find(word1)
                if word1_pos != -1:
                    word2_pos = text_lower.find(word2, word1_pos)
                    if word2_pos != -1 and word2_pos - word1_pos < 50:
                        score += 0.3
        
        return min(score, 2.0)  # æœ€å¤§ã‚¹ã‚³ã‚¢åˆ¶é™
    
    def _highlight_query_in_text(self, text: str, query: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ã‚¯ã‚¨ãƒªã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ"""
        if not text or not query:
            return text
        
        # ç°¡æ˜“ãƒã‚¤ãƒ©ã‚¤ãƒˆå®Ÿè£…
        query_words = query.split()
        highlighted_text = text
        
        for word in query_words:
            # å¤§æ–‡å­—å°æ–‡å­—ã‚’ç„¡è¦–ã—ã¦ç½®æ›
            pattern = re.compile(re.escape(word), re.IGNORECASE)
            highlighted_text = pattern.sub(f"**{word}**", highlighted_text)
        
        return highlighted_text
    
    def _generate_search_stats(self, results: List[SearchResult], filters: SearchFilters) -> str:
        """æ¤œç´¢çµ±è¨ˆã®ç”Ÿæˆ"""
        if not results:
            return ""
        
        stats = {
            "conversation": 0,
            "persona": 0,
            "vector_store": 0
        }
        
        for result in results:
            stats[result.result_type] = stats.get(result.result_type, 0) + 1
        
        message = "## ğŸ“Š æ¤œç´¢çµ±è¨ˆ\n\n"
        message += f"- ğŸ’¬ ä¼šè©±å±¥æ­´: {stats['conversation']}ä»¶\n"
        message += f"- ğŸ­ ãƒšãƒ«ã‚½ãƒŠ: {stats['persona']}ä»¶\n"
        message += f"- ğŸ—‚ï¸ ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢: {stats['vector_store']}ä»¶\n"
        
        if filters:
            message += "\n**é©ç”¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼:**\n"
            if filters.start_date:
                message += f"- é–‹å§‹æ—¥: {filters.start_date[:10]}\n"
            if filters.end_date:
                message += f"- çµ‚äº†æ—¥: {filters.end_date[:10]}\n"
            if filters.persona_names:
                message += f"- ãƒšãƒ«ã‚½ãƒŠ: {', '.join(filters.persona_names)}\n"
            if filters.models:
                message += f"- ãƒ¢ãƒ‡ãƒ«: {', '.join(filters.models)}\n"
        
        return message


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
search_handler = SearchHandler()